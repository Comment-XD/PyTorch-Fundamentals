{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b42563",
   "metadata": {},
   "source": [
    "### Pipeline Structure\n",
    "\n",
    "1. Retrieve Data\n",
    "    - Find letter images and retrieve them\n",
    "    \n",
    "2. Data Augmentation\n",
    "   - Contour the images \n",
    "   - Increase the brightness\n",
    "    <br></br>\n",
    "3. CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef73eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brand\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Brand\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6983397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(r\"C:\\Users\\Brand\\Documents\\Branden's Stuff\\Python\\Machine Learning\\data\")\n",
    "letter_data_path = data_path / \"A_Z Handwritten Data.csv\"\n",
    "\n",
    "letter_data = pd.read_csv(letter_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eb7372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372450"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a280227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = letter_data[\"0\"]\n",
    "X = letter_data.drop(columns=[\"0\"]) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d80d6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'digit_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdigit_train_data\u001b[49m\u001b[38;5;241m.\u001b[39mlabels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'digit_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(digit_train_data.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf064e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_image(images, images_labels, seed=42, plot_dim=(4,4)):\n",
    "    height, width = plot_dim\n",
    "    fig, ax = plt.subplots(height, width, figsize=(16,8))\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    alphabets = {i: string.ascii_lowercase[i] for i in range(0, 26)}\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            m,_ = X.shape\n",
    "            random_num = np.random.randint(0, m)\n",
    "\n",
    "            img = images.iloc[random_num].to_numpy().reshape(28, 28)\n",
    "            img_label = images_labels.iloc[random_num]\n",
    "\n",
    "            ax[i, j].set_title(alphabets[img_label])\n",
    "            ax[i, j].imshow(img, cmap=\"gray\")\n",
    "            ax[i, j].axis(False)\n",
    "\n",
    "viz_image(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_params = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean=[0.485],\n",
    "                         std=[0.229])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Letter_Dataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, target_transform=None):\n",
    "        self.df = torch.tensor(X.to_numpy().reshape(self.__len__(), 1,28,28)).to(torch.float32)\n",
    "        \n",
    "        self.df_labels = y\n",
    "        self.labels = self.df_labels.to_numpy()\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if self.transform:\n",
    "            self.transform(self.df)\n",
    "            \n",
    "        return self.df[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, _ = letter_data.shape\n",
    "threshold = 0.6\n",
    "\n",
    "\n",
    "train_data, test_data = letter_data[0: int(m * 0.6)], letter_data[int(m * 0.6): m]\n",
    "\n",
    "digit_train_data = Letter_Dataset(X_train, y_train)\n",
    "digit_test_data = Letter_Dataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(digit_train_data, batch_size=8, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(digit_test_data, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "train_feature, train_label = next(iter(train_dataloader))\n",
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Letter_Classification_Model(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_0 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, \n",
    "                      out_channels=6, \n",
    "                      kernel_size=5),\n",
    "            \n",
    "            nn.AvgPool2d(kernel_size=2, \n",
    "                         stride=2),\n",
    "            \n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, \n",
    "                      out_channels=16,\n",
    "                      kernel_size=5),\n",
    "            \n",
    "            nn.AvgPool2d(kernel_size=2,\n",
    "                         stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, output_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_0(x)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_model = Letter_Classification_Model(1, 26)\n",
    "\n",
    "print(torch.sum(letter_model.forward(train_feature).argmax(dim=1) == train_label).numpy() / 8)\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd81394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = Accuracy(task=\"multiclass\", num_classes=26)\n",
    "\n",
    "\n",
    "optimizer = SGD(letter_model.parameters(), lr=0.1)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=letter_model,\n",
    "        input_size=(64, 1, 28, 28),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=15,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def train_test_process(model,\n",
    "                       train_dataloader: DataLoader, \n",
    "                       test_dataloader: DataLoader, \n",
    "                       optimizer, \n",
    "                       loss_fn, \n",
    "                       epochs: int):\n",
    "    \n",
    "    # sets the model to train mode\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        print(f\"Epoch: {epoch}\\n-------\")\n",
    "        train_loss = 0\n",
    "        for batch, (X,y) in enumerate(train_dataloader):\n",
    "            \n",
    "            # forward propogation, gets the predicted y value\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # calculates the loss using cross entropy\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "\n",
    "            # zeros the the gradients from before\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # goes on to the next \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "\n",
    "                # Print out how many samples have been seen\n",
    "            if batch % 4000 == 0:\n",
    "                print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "        \n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        # sets the model to evaluation mode\n",
    "        model.eval()\n",
    "        test_accuracy, test_loss = 0,0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X,y in test_dataloader:\n",
    "                y_pred = model(X)\n",
    "                \n",
    "                test_loss += loss_fn(y_pred, y)\n",
    "                test_accuracy += torch.sum(y_pred.argmax(dim=1) == y).numpy() / 8\n",
    "                print(y_pred.argmax(dim=1), y)\n",
    "\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_accuracy /= len(test_dataloader)\n",
    "\n",
    "        print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_process(model=letter_model,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=cross_entropy_loss,\n",
    "                  epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5dba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
