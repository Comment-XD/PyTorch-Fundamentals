{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac151fda-a9f6-4f14-8edf-e5ec088cbd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brand\\AppData\\Local\\Temp\\ipykernel_14508\\666172156.py:22: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Data Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Image Processing Libraries\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File Automation Libraires\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29885e0-7b6c-46e3-9c02-5a1336bd0a73",
   "metadata": {},
   "source": [
    "1. **Creating a Custom Dataset with PyTorch**\r\n",
    "    - Understanding what a Custom Dataset is\r\n",
    "    - Learning how to Create a Custom Dataset\r\n",
    "    <br></br>\r\n",
    "    \r\n",
    "2. **Understanding Batching**\r\n",
    "    <br></br>\r\n",
    "    <pre>\r\n",
    "    tab level 0\r\n",
    "        tab level 1\r\n",
    "                tab level 2\r\n",
    "    </pre>\r\n",
    "\r\n",
    "3. **Understanding Conv2D**\r\n",
    "    - In & out channels\r\n",
    "    - Understanding how the hyperparameters effect the image processing\r\n",
    "    <br></br>\r\n",
    "4. **Understanding Max and Mean Pooling**\r\n",
    "    - Understanding how the hyperparameters effect the image processing\r\n",
    "    <br></br>\r\n",
    "\r\n",
    "5. **How to Flatten the Image and Use a Linear Layer**\r\n",
    "    - Using the **`Flatten`** class from **`torch.nn`** we are going to flatten the image to a 1-D vector\r\n",
    "    - This allows us to do a fully-connected layer and return an output layer with the same dimension as the `output_shape`\r\n",
    "    <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b75a20-f044-4392-b2d6-37680476a5d8",
   "metadata": {},
   "source": [
    "### Batching\r\n",
    "\r\n",
    "- Batching is the process of clustering datapoints into groups\r\n",
    "- This allows faster training time, and more effecient training\r\n",
    "- In `torch.utils.data`, there is a class called `DataLoader` allows us to make batches of data from a large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018b5f2c-4b1f-4ea0-a31d-583761f79fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches of RGB Images -> 32\n",
      "Images Size: torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = (32, 3, 64, 64) #[batch_size, color_channels, height, width]\n",
    "\n",
    "images = torch.randn(size=IMAGE_SIZE) \n",
    "\n",
    "# each image has three channels (RGB) and each image is 64x64\n",
    "# for this example above, there are 32 of these 3 channel image that have a shape of (64,64)\n",
    "print(f\"Number of Batches of RGB Images -> {len(images)}\") \n",
    "\n",
    "\n",
    "# changes the number of batches\n",
    "batch_images = DataLoader(images, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch_feature_image = next(iter(batch_images))\n",
    "print(f\"Images Size: {batch_feature_image.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781ba9f-f16b-471d-b2e5-3df29fe3b80b",
   "metadata": {},
   "source": [
    "### Conv2D\r\n",
    "- In **`torch.nn`**,  **`conv2d`** is used to process 2D images \r\n",
    "\r\n",
    "**Parameters** \r\n",
    "   - **`in_channels`**: Number of channels in this picture (RGB = 3 channels), (Grey Scaling = 1 channel)\r\n",
    "   - **`out_channels`**: Number of created channels after running through the Conv Layer\r\n",
    "   - **`kernel_size`**: Dimension of a filter you want to extract from the image\r\n",
    "   - **`stride`**: How big of a step does the kernel/filter scan through the image\r\n",
    "   - **`padding`**: Increases how much of a \r\n",
    "\r\n",
    "**Input**\r\n",
    "   - Takes in a **`[batch_size, color_channels, height, width]`** \r\n",
    "   - You can use methods like **`unsqueeze(dim=0)`** to increase the dimension by one\r\n",
    "    \r\n",
    "    \r\n",
    "### What are Channels?\r\n",
    "- Channels are used to represent the number of primary colors are in an image\r\n",
    "\r\n",
    "**Examples**\r\n",
    "   - **`GreyScale Images`**: Only have one channel\r\n",
    "   - **`Digital Images`**: Only have three channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c822317f-9baf-4271-8d19-5c0b28dfad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image Shape: torch.Size([3, 64, 64])\n",
      "Image Shape After Conv2D: torch.Size([10, 35, 35])\n"
     ]
    }
   ],
   "source": [
    "test_image = images[0]\n",
    "print(f\"Original Image Shape: {test_image.size()}\")\n",
    "\n",
    "conv2d = Conv2d(in_channels=3,\n",
    "                out_channels=10, # Creates more filters / kernels, allowing to gather more information from the info,\n",
    "                kernel_size=(4,4), # Increasing kernal_size means a smaller image shape,\n",
    "                stride=2, # Increasing stride means a smaller image shape,\n",
    "                padding=4) # Increasing padding means a greater image shape)\n",
    "\n",
    "\n",
    "test_image_conv2d = conv2d(test_image.unsqueeze(dim=0))\n",
    "print(f\"Image Shape After Conv2D: {test_image_conv2d.squeeze(dim=0).size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64135e47-a319-479b-9948-923cdc60a9d1",
   "metadata": {},
   "source": [
    "### MaxPooling and Mean Pooling\r\n",
    "- Pooling is used to find more information in images after the conv layer \r\n",
    "- In **`torch.nn`**,  **`MaxPool2d`** and **`AvgPool2d`** are commonly used for pooling\r\n",
    "\r\n",
    "**Mean Pooling**\r\n",
    "   - Mean Pooling is the same as a filter in Conv2D but unlike trainable parameters, it takes the mean values for the values it scan and returns it  \r\n",
    "   \r\n",
    "\r\n",
    "   1. **`AvgPool2d`** Parameters\r\n",
    "       - **`kernel_size`**: Dimension of a filter you want to extract from the image\r\n",
    "       - **`stride`**: How big of a step does the kernel/filter scan through the image\r\n",
    "       - **`padding`**: Puts null values around the images\r\n",
    "    \r\n",
    "**Max Pooling**\r\n",
    "   - Max Pooling is the same as a filter in Conv2D but unlike trainable parameters, it takes the max values for the values it scan and returns it  \r\n",
    "   - More commonly used for object detection\r\n",
    "   \r\n",
    "   1. **`MaxPool2d`** Parameters\r\n",
    "       - **`kernel_size`**: Dimension of a filter you want to extract from the image\r\n",
    "       - **`stride`**: How big of a step does the kernel/filter scan through the image\r\n",
    "       - **`padding`**: Puts null values around the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ee6d48-b251-4656-a950-d58fa861805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape After Conv2D: torch.Size([10, 35, 35])\n",
      "Image Shape After MaxPool2D: torch.Size([10, 33, 33])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image Shape After Conv2D: {test_image_conv2d.squeeze(dim=0).size()}\")\n",
    "max_pool = MaxPool2d(kernel_size=3, # Increasing kernel_size means a smaller image shape\n",
    "                     stride=1) # Increasing stride means a smaller image shape\n",
    "\n",
    "test_image_maxpool = max_pool(test_image_conv2d)\n",
    "print(f\"Image Shape After MaxPool2D: {test_image_maxpool.squeeze(dim=0).shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
