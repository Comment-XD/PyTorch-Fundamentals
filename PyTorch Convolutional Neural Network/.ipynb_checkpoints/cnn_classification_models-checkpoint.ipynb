{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4527acf9-f4ca-4cd4-a7a4-828bd6ef35b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda as cuda\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "#import timm # Unofficial pytorch image models, for comparison\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use Nvidia GPU if available, for faster results\n",
    "# Uncomment below to verify cuda is working\n",
    "device\n",
    "# print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7713e91-c47a-437d-ba95-dea7a41986db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations that will be applied to the images during the loading process\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Mean and Std. Dev values used here are commonly used with the ImageNet dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6242e318-4d2b-489d-9f68-01379674c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Settings\n",
    "batch_size = 32 # This should usually be kept to a size that is a power of two\n",
    "epochs = 15 # Need to monitor validation loss during training to avoid overfitting https://datascience.stackexchange.com/questions/46523/is-a-large-number-of-epochs-good-or-bad-idea-in-cnn\n",
    "lr = 3e-5 # Need to implement learning rate decay \n",
    "gamma = 0.7\n",
    "seed = 2147483647\n",
    "# We'll use a PyTorch Generator to make things repeatable (deterministic)\n",
    "g = torch.Generator().manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d04b3d9-e55c-4711-ae1a-78a5d7c7132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to dataset\n",
    "dataset_path = r\"C:\\Users\\Brand\\Documents\\Branden's Stuff\\Python\\BusyBee\\data\\images\"\n",
    "\n",
    "# Load Datasets with labels\n",
    "dset = datasets.ImageFolder(dataset_path, transform=transform) # Automatially assigns labels to examples based on the directory name\n",
    "\n",
    "# Generate 2 splits: Train (80%), Test (20%)\n",
    "dset_size = len(dset)\n",
    "train_size = int(0.8 * dset_size)\n",
    "test_size = dset_size - train_size\n",
    "\n",
    "train, test = torch.utils.data.random_split(dset, [train_size, test_size], generator=g)\n",
    "\n",
    "# Create Data Loaders fro splits\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa05c1b-63a6-4194-91e8-bccedcd77bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = len(dset.classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7be2e5e-bda4-488a-9c87-586e5db5f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Statistics Init\n",
    "loss_dict = {}\n",
    "accuracy_dict = {}\n",
    "time_to_train_dict = {}\n",
    "test_accuracy_dict = {}\n",
    "\n",
    "def train_model(model, name):\n",
    "    \"\"\"\n",
    "    Going to tweak this to where we can see the train and test loss over the incrementation so we can see how clearly a model is over fitting or underfitting\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Loss Function\n",
    "    criterion = nn.CrossEntropyLoss() # creates the loss function\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # optimization function\n",
    "    # Scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma) # Learning rate decay function\n",
    "    print(\"\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Training Run [Model: {name}]\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "    # Training Statistics Init\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    # Training Time\n",
    "    start_event = cuda.Event(enable_timing=True)\n",
    "    end_event = cuda.Event(enable_timing=True)\n",
    "    # Begin Clock\n",
    "    start_event.record()\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        \n",
    "        for data, label in tqdm(train_dl):\n",
    "            data = data.to(device) # Ensure we're processing data on GPU\n",
    "            label = label.to(device)\n",
    "        \n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "        \n",
    "            optimizer.zero_grad() # Zero out the gradient -- we'll experience weird bugs if we forget to do so\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            acc = (output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_accuracy += acc / len(train_dl)\n",
    "            epoch_loss += loss / len(train_dl)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1} - loss: {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}\")\n",
    "        loss_list.append(epoch_loss.cpu().detach().numpy().item())\n",
    "        accuracy_list.append(epoch_accuracy.cpu().detach().numpy().item())\n",
    "       \n",
    "    # End Clock\n",
    "    end_event.record()\n",
    "    cuda.synchronize() # Wait for GPU operations to complete\n",
    "    time = start_event.elapsed_time(end_event) / 1000 # Convert to seconds\n",
    "    num_examples = batch_size * len(train_dl)\n",
    "    time_per_example = time / (num_examples * epochs)\n",
    "    print(f\"It took {time} seconds to train {name} on {num_examples} examples over {epochs} epochs.\")\n",
    "    print(f\"That averages to {time_per_example} seconds per example\")\n",
    "\n",
    "    # Test run\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Test Run [Model: {name}] \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++\")\n",
    "    accuracies = []\n",
    "    batch_acc = 0\n",
    "    for data, label in tqdm(test_dl):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(data)\n",
    "        acc = (output.argmax(dim=1) == label).float().mean().cpu().detach().numpy()\n",
    "        batch_acc += acc / len(test_dl)\n",
    "        accuracies.append(batch_acc)\n",
    "        \n",
    "    print(f\"Test Accuracy: {accuracies[-1]} - Number of test cases: {len(test_dl) * batch_size}\")\n",
    "\n",
    "    # Update training stats\n",
    "    loss_dict.update({name: loss_list})\n",
    "    accuracy_dict.update({name: accuracy_list})\n",
    "    time_to_train_dict.update({name: time_per_example})\n",
    "    test_accuracy_dict.update({name: accuracies[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48631953-94c8-4b07-8860-60086f0fba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Conv2d (conv1)                         [32, 3, 224, 224]    [32, 64, 112, 112]   9,408                True\n",
       "├─BatchNorm2d (bn1)                      [32, 64, 112, 112]   [32, 64, 112, 112]   128                  True\n",
       "├─ReLU (relu)                            [32, 64, 112, 112]   [32, 64, 112, 112]   --                   --\n",
       "├─MaxPool2d (maxpool)                    [32, 64, 112, 112]   [32, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer1)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   True\n",
       "│    └─BasicBlock (0)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    └─BasicBlock (1)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer2)                    [32, 64, 56, 56]     [32, 128, 28, 28]    --                   True\n",
       "│    └─BasicBlock (0)                    [32, 64, 56, 56]     [32, 128, 28, 28]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 128, 28, 28]    73,728               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    256                  True\n",
       "│    │    └─Sequential (downsample)      [32, 64, 56, 56]     [32, 128, 28, 28]    8,448                True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 128, 28, 28]    [32, 128, 28, 28]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 28, 28]    [32, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "├─Sequential (layer3)                    [32, 128, 28, 28]    [32, 256, 14, 14]    --                   True\n",
       "│    └─BasicBlock (0)                    [32, 128, 28, 28]    [32, 256, 14, 14]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 28, 28]    [32, 256, 14, 14]    294,912              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    512                  True\n",
       "│    │    └─Sequential (downsample)      [32, 128, 28, 28]    [32, 256, 14, 14]    33,280               True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 256, 14, 14]    [32, 256, 14, 14]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 14, 14]    [32, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "├─Sequential (layer4)                    [32, 256, 14, 14]    [32, 512, 7, 7]      --                   True\n",
       "│    └─BasicBlock (0)                    [32, 256, 14, 14]    [32, 512, 7, 7]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 14, 14]    [32, 512, 7, 7]      1,179,648            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─Sequential (downsample)      [32, 256, 14, 14]    [32, 512, 7, 7]      132,096              True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    └─BasicBlock (1)                    [32, 512, 7, 7]      [32, 512, 7, 7]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 7, 7]      [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [32, 512, 7, 7]      [32, 512, 1, 1]      --                   --\n",
       "├─Linear (fc)                            [32, 512]            [32, 1000]           513,000              True\n",
       "========================================================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 58.05\n",
       "========================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 1271.92\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 1337.94\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet - 18\n",
    "res_net_18_weights = models.ResNet18_Weights.DEFAULT\n",
    "res_net_18 = models.resnet18(weights=res_net_18_weights).to(device)\n",
    "# num_ftrs = res_net_18.fc.in_features\n",
    "\n",
    "summary(model=res_net_18, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263af09-dc7b-4d02-a20b-b4e796a3449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusyBee_ResNet18(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c943f983-5ead-4136-aa20-b49d9fd7a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in res_net_18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93320990-65fd-4e48-81ad-4f6bd9be5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in res_net_18.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61914038-9a1d-4cbe-ae3a-8345cb67c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net_18.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757fd65a-d0c1-448e-ba62-67a365851efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Training Run [Model: ResNet 18]\n",
      "++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb3f266e96f4bc895119b4a2fb82e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 1.7785 - acc: 0.4616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867b7286aecf4200930fb00c36a07cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - loss: 1.0628 - acc: 0.6561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9cac0b1d304fb688c8b9f86f794d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 - loss: 0.7263 - acc: 0.7743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f517f8523e5748d4a42da216a06af23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 - loss: 0.4605 - acc: 0.8775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6c26105f9a4a41b4e017d8502d2162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - loss: 0.2809 - acc: 0.9340\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a09a3c64034121b3709e0281715be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 - loss: 0.1900 - acc: 0.9579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9765e8e0826b4eafa1d55dd6858a5119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 - loss: 0.1429 - acc: 0.9698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9fa89cd05742f596a1eaa6c65b950e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 - loss: 0.1182 - acc: 0.9722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35524388b9f84f3abef599c74cd82079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 - loss: 0.1010 - acc: 0.9738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bdfdf2eb2c4137a036477d86f1df3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - loss: 0.0894 - acc: 0.9736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd974a912dc143f2993aa69eaa0a1ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 - loss: 0.0785 - acc: 0.9757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bba15919b274164a47561eb3e3bae4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 - loss: 0.0675 - acc: 0.9761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a668f58d7b1242f5b4bd1c7ee9474fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 - loss: 0.0637 - acc: 0.9751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80429b8070b349bdb54b37dfc93ddfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 - loss: 0.0603 - acc: 0.9769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a60a76d6c8d4fba828e27c4d31b245a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 - loss: 0.0558 - acc: 0.9761\n",
      "It took 370.63734375 seconds to train ResNet 18 on 9408 examples over 15 epochs.\n",
      "That averages to 0.002626398410926871 seconds per example\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Test Run [Model: ResNet 18] \n",
      "++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caad9b37d66e4f40bdf0933899815ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5740939805636533 - Number of test cases: 2368\n"
     ]
    }
   ],
   "source": [
    "train_model(res_net_18, \"ResNet 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0012257e-09a6-4f8b-9cde-7b576f97bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model_name, model):\n",
    "    MODEL_PATH = Path(\"models\")\n",
    "    \n",
    "    if not os.path.exists(\"models\"):\n",
    "        MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    else:\n",
    "        MODEL_SAVE_PATH = MODEL_PATH / f\"{model_name}.pth\"\n",
    "        torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
    "\n",
    "def load(model_name, model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a7a8d8e-78fa-491e-97bf-4dbc0bf991eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busy_bee_weights = torch.load(f=MODEL_SAVE_PATH)\n",
    "\n",
    "busy_bee = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)\n",
    "busy_bee.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "busy_bee.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1a906-d6d4-43bf-968b-7553c6ed9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Training Run [Model: alexnet]\n",
      "++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da10023d18b4b2ba9e57f64266d26ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 1.6504 - acc: 0.4179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b5d2538b5d4465bae55f2094e9dabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - loss: 1.4334 - acc: 0.4760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173541e5a65e49d6922db92123ab5341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 - loss: 1.3235 - acc: 0.5130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1528d2d972948b39989d34926d4e8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 - loss: 1.2299 - acc: 0.5482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9cc6e972ae487fb61f8a3b3276e983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - loss: 1.1535 - acc: 0.5790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28809390247345489430b75b04df4a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 - loss: 1.0717 - acc: 0.6063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61257cba446433db1e5af0fb285cf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 - loss: 0.9971 - acc: 0.6324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9968f87e514ca4bb7a79f315dd69f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 - loss: 0.9161 - acc: 0.6652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f911697ff8c45879fe6c174618bdf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 - loss: 0.8598 - acc: 0.6884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c14d80aa1da4bf8929d4bf0e249d412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - loss: 0.7946 - acc: 0.7182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac0e0f5a56e41868de835e3fc87b22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 - loss: 0.7357 - acc: 0.7351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c3f348dcf44a638d69501cc55e293b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 - loss: 0.6867 - acc: 0.7567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c227228e5f48a7a6e517e9f168b6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resnet - 50\n",
    "alexnet_weights = torchvision.models.AlexNet_Weights\n",
    "alexnet = torchvision.models.alexnet(weights=alexnet_weights).to(device)\n",
    "num_ftrs = alexnet.classifier[-1].in_features\n",
    "# # Here the size of each output sample is set to 2.\n",
    "# # Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in alexnet.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "alexnet.classifier[-1] = nn.Linear(num_ftrs, classes).to(device)\n",
    "\n",
    "train_model(alexnet, \"alexnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4e4b0b7-9ee9-4688-8373-eb21f203cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"alexnet\", alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3904c1a-f229-4eb9-979d-558aa5f4056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusyBee_CNN: \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.__models = os.listdir() # this should be predefined\n",
    "        self.__model_save_path\n",
    "        \"\"\"\n",
    "        Create a dictionary with all of the train models save path, and model_type:\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "        self.models = { resnet18: (model/resnet18, models.resnet18(weights=models.ResNet)),\n",
    "                        resnet50: model/resnet50,\n",
    "                        alexnet: model/alexnet,\n",
    "                        lenet: model/lenet,\n",
    "                        vgg16: model/vgg16,\n",
    "                        vgg19: model/vgg19\n",
    "                      }\n",
    "        \n",
    "        ^ Should be a static variable so we can add more models in the future?\n",
    "            > CNN_Busy_Models.add(model_name, savepath) # something like this\n",
    "            > Rebute, self.models should not be declared inside the class but should obtain those models from an external source (folder / db)\n",
    "\n",
    "\n",
    "        What do I want BusyBee_CNN to return?\n",
    "        - A model with the pretrained weights\n",
    "\n",
    "        What external functionality do I want BusyBee_CNN to have?\n",
    "        - Architecture, using torchinfo.summary (.struct?)\n",
    "        - Metrics, Train Loss, Test Loss Graphs (.metrics)\n",
    "        - User has the option to add their models to the models folder (.add )\n",
    "\n",
    "        What internal functionalality do I want BusyBee_CNN to have?\n",
    "        - load models using savepath\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def __load__(self):\n",
    "        \"\"\"\n",
    "        Loads a model from busybee, private method\n",
    "        \"\"\"\n",
    "        busy_bee_weights = torch.load(f=self.__model_save_path)\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def add(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def summary(self):\n",
    "        pass\n",
    "\n",
    "    def metrics(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
