{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88bb4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "# import torchmetrics \n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365f67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the path of the data folder\n",
    "\n",
    "data_path = Path(r\"C:\\Users\\Brand\\Documents\\Branden's Stuff\\Python\\Machine Learning\\data\")\n",
    "iris_path = data_path / \"iris.data\"\n",
    "\n",
    "iris_data = pd.read_csv(iris_path)\n",
    "\n",
    "# Preprocessing for labels\n",
    "le = LabelEncoder()\n",
    "iris_data[\"class\"] = le.fit_transform(iris_data[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3318097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in length</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in length  petal length in cm  \\\n",
       "0                   4.7                    3.2                 1.3   \n",
       "1                   4.6                    3.1                 1.5   \n",
       "2                   5.0                    3.6                 1.4   \n",
       "3                   5.4                    3.9                 1.7   \n",
       "4                   4.6                    3.4                 1.4   \n",
       "..                  ...                    ...                 ...   \n",
       "143                 6.7                    3.0                 5.2   \n",
       "144                 6.3                    2.5                 5.0   \n",
       "145                 6.5                    3.0                 5.2   \n",
       "146                 6.2                    3.4                 5.4   \n",
       "147                 5.9                    3.0                 5.1   \n",
       "\n",
       "     petal width in cm  class  \n",
       "0                  0.2      0  \n",
       "1                  0.2      0  \n",
       "2                  0.2      0  \n",
       "3                  0.4      0  \n",
       "4                  0.3      0  \n",
       "..                 ...    ...  \n",
       "143                2.3      2  \n",
       "144                1.9      2  \n",
       "145                2.0      2  \n",
       "146                2.3      2  \n",
       "147                1.8      2  \n",
       "\n",
       "[148 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bafc3b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in length</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in length  petal length in cm  \\\n",
       "44                  5.1                    3.8                 1.6   \n",
       "15                  5.1                    3.5                 1.4   \n",
       "101                 6.3                    2.9                 5.6   \n",
       "39                  4.5                    2.3                 1.3   \n",
       "68                  5.9                    3.2                 4.8   \n",
       "..                  ...                    ...                 ...   \n",
       "71                  6.1                    2.8                 4.7   \n",
       "106                 6.7                    2.5                 5.8   \n",
       "14                  5.4                    3.9                 1.3   \n",
       "92                  5.6                    2.7                 4.2   \n",
       "102                 6.5                    3.0                 5.8   \n",
       "\n",
       "     petal width in cm  class  \n",
       "44                 0.2      0  \n",
       "15                 0.3      0  \n",
       "101                1.8      2  \n",
       "39                 0.3      0  \n",
       "68                 1.8      1  \n",
       "..                 ...    ...  \n",
       "71                 1.2      1  \n",
       "106                1.8      2  \n",
       "14                 0.4      0  \n",
       "92                 1.3      1  \n",
       "102                2.2      2  \n",
       "\n",
       "[88 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the dataset for training and testing \n",
    "threshold = 0.6\n",
    "y = iris_data[\"class\"]\n",
    "X = iris_data.drop(columns=[\"class\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.6, test_size=0.4, random_state=42)\n",
    "\n",
    "pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a34e",
   "metadata": {},
   "source": [
    "### Custom Dataset\n",
    "- The purpose of the custom dataset for PyTorch is to upload it into the dataloader\n",
    "- Requires three methods to inherit **`__init__`**, **`__len__`**, **`__getitem__`**\n",
    "<br> </br>\n",
    "1. **__init__ `(Constructor)`**\n",
    "    - Requires the data and if required, preprocess the data\n",
    "    - Seperate the data into the features and the labels\n",
    "    - Convert them into the approporate data types **`(floats or long)`**\n",
    "    <br></br>\n",
    "2. **__len__ `(Length)`**\n",
    "    - Returns the length of the dataset\n",
    "    <br></br>\n",
    "3. **__getitem__ `(Index)`**\n",
    "    - Returns the features and labels of the dataset at a specific index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "063316a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisFlowerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.df = X\n",
    "        self.df_labels = y\n",
    "        self.dataset = torch.tensor(self.df.to_numpy()).float()\n",
    "        self.labels = torch.tensor(self.df_labels.to_numpy()).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[i], self.labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e81019",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train_dataset = IrisFlowerDataset(X_train, y_train)\n",
    "iris_test_dataset = IrisFlowerDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a5cc7",
   "metadata": {},
   "source": [
    "### Dataset Loader\n",
    "- The purpose of dataset loader is to convert the dataset into mini batches\n",
    "- Has many parameters to go over but **`num_workers`**, **`batch_size`**, **`drop_last`**, **`shuffle`** are some of the more important parameters\n",
    "<br> </br>\n",
    "1. **`num_workers`**\n",
    "    - Increases the capacity of parallelism\n",
    "    - The more workers there are, the faster the dataset is converted\n",
    "    - However, this requires more memory to implement\n",
    "    <br></br>\n",
    "2. **`batch_size`**\n",
    "    - Determines the size of each batch in the dataset\n",
    "    <br></br>\n",
    "3. **`shuffle`**\n",
    "    - Shuffles the dataset before picking a data for its batches\n",
    "    <br></br>\n",
    "4. **`drop_last`**\n",
    "    - Drops the batches that are not consistent with the batch size\n",
    "    - Example: length of dataset is 130, want to create batch_size of 30, (30, 30, 30, 30, 10), results in the dropping of the batch_size of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5946ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(iris_train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(iris_test_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "train_feature, train_label = next(iter(train_dataloader))\n",
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aba62e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisModel(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(input_shape, 20),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(20, output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.hidden_layer(x)\n",
    "    \n",
    "iris_model = IrisModel(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b212700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a83c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_test_process(model: nn.Module,\n",
    "                      train_dataloader: DataLoader,\n",
    "                      test_dataloader: DataLoader,\n",
    "                      optimizer: SGD,\n",
    "                      loss_fn: nn.CrossEntropyLoss,\n",
    "                      epochs: int):\n",
    "    \n",
    "    test_accuracy_record = []\n",
    "    \n",
    "    for i in tqdm(range(epochs)):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch, (X,y) in enumerate(train_dataloader):\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            \n",
    "            train_loss += loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss /= len(train_dataloader)\n",
    "    \n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            test_accuracy, test_loss = 0,0\n",
    "            \n",
    "            for X,y in test_dataloader:\n",
    "                y_pred = model(X)\n",
    "\n",
    "                test_loss += loss_fn(y_pred, y)\n",
    "                test_accuracy += sum(y == y_pred.argmax(dim=-1)).numpy() / 8\n",
    "\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_accuracy /= len(test_dataloader) \n",
    "\n",
    "            test_accuracy_record.append(test_accuracy)\n",
    "        if i % 100 == 0 or i == epochs - 1:\n",
    "            print(f\"EPOCH: {i} \\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_accuracy * 100:.2f}%\\n\")\n",
    "    return test_accuracy_record\n",
    "\n",
    "def predict(test_data, test_label, model):\n",
    "    y_pred = model.forward(test_data).argmax(dim=-1)\n",
    "    print(y_pred, test_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b02eeb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafe1f8cb67b44cb924df2c42cb2f90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 \n",
      "Train loss: 0.58559 | Test loss: 0.51118, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 10 \n",
      "Train loss: 0.56035 | Test loss: 0.49674, Test acc: 92.86%\n",
      "\n",
      "EPOCH: 20 \n",
      "Train loss: 0.53817 | Test loss: 0.48007, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 30 \n",
      "Train loss: 0.56320 | Test loss: 0.47172, Test acc: 92.86%\n",
      "\n",
      "EPOCH: 40 \n",
      "Train loss: 0.51319 | Test loss: 0.46118, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 50 \n",
      "Train loss: 0.55337 | Test loss: 0.45337, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 60 \n",
      "Train loss: 0.52308 | Test loss: 0.43372, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 70 \n",
      "Train loss: 0.52344 | Test loss: 0.42988, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 80 \n",
      "Train loss: 0.46299 | Test loss: 0.41231, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 90 \n",
      "Train loss: 0.48415 | Test loss: 0.39845, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 100 \n",
      "Train loss: 0.43999 | Test loss: 0.39778, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 110 \n",
      "Train loss: 0.43332 | Test loss: 0.39951, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 120 \n",
      "Train loss: 0.46183 | Test loss: 0.38756, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 130 \n",
      "Train loss: 0.44895 | Test loss: 0.38609, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 140 \n",
      "Train loss: 0.43062 | Test loss: 0.37634, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 150 \n",
      "Train loss: 0.42527 | Test loss: 0.38742, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 160 \n",
      "Train loss: 0.45095 | Test loss: 0.36147, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 170 \n",
      "Train loss: 0.40864 | Test loss: 0.35129, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 180 \n",
      "Train loss: 0.41529 | Test loss: 0.36014, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 190 \n",
      "Train loss: 0.39456 | Test loss: 0.34716, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 200 \n",
      "Train loss: 0.40738 | Test loss: 0.34490, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 210 \n",
      "Train loss: 0.37876 | Test loss: 0.34900, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 220 \n",
      "Train loss: 0.37297 | Test loss: 0.32033, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 230 \n",
      "Train loss: 0.37644 | Test loss: 0.31956, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 240 \n",
      "Train loss: 0.39090 | Test loss: 0.32442, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 250 \n",
      "Train loss: 0.36796 | Test loss: 0.31705, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 260 \n",
      "Train loss: 0.37702 | Test loss: 0.32006, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 270 \n",
      "Train loss: 0.37884 | Test loss: 0.30724, Test acc: 96.43%\n",
      "\n",
      "EPOCH: 280 \n",
      "Train loss: 0.41109 | Test loss: 0.29922, Test acc: 94.64%\n",
      "\n",
      "EPOCH: 290 \n",
      "Train loss: 0.33338 | Test loss: 0.29738, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 300 \n",
      "Train loss: 0.31975 | Test loss: 0.31229, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 310 \n",
      "Train loss: 0.35463 | Test loss: 0.29028, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 320 \n",
      "Train loss: 0.31771 | Test loss: 0.29074, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 330 \n",
      "Train loss: 0.34187 | Test loss: 0.29037, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 340 \n",
      "Train loss: 0.30558 | Test loss: 0.28367, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 350 \n",
      "Train loss: 0.29165 | Test loss: 0.28815, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 360 \n",
      "Train loss: 0.35161 | Test loss: 0.27532, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 370 \n",
      "Train loss: 0.32629 | Test loss: 0.25855, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 380 \n",
      "Train loss: 0.36482 | Test loss: 0.27239, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 390 \n",
      "Train loss: 0.32796 | Test loss: 0.27364, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 400 \n",
      "Train loss: 0.30051 | Test loss: 0.26901, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 410 \n",
      "Train loss: 0.27560 | Test loss: 0.25798, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 420 \n",
      "Train loss: 0.27749 | Test loss: 0.26274, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 430 \n",
      "Train loss: 0.27614 | Test loss: 0.25776, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 440 \n",
      "Train loss: 0.27094 | Test loss: 0.24938, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 450 \n",
      "Train loss: 0.27527 | Test loss: 0.24703, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 460 \n",
      "Train loss: 0.28735 | Test loss: 0.25014, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 470 \n",
      "Train loss: 0.29045 | Test loss: 0.24804, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 480 \n",
      "Train loss: 0.26711 | Test loss: 0.23851, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 490 \n",
      "Train loss: 0.26181 | Test loss: 0.25154, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 500 \n",
      "Train loss: 0.26891 | Test loss: 0.24700, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 510 \n",
      "Train loss: 0.27679 | Test loss: 0.24936, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 520 \n",
      "Train loss: 0.24927 | Test loss: 0.23809, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 530 \n",
      "Train loss: 0.26218 | Test loss: 0.22694, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 540 \n",
      "Train loss: 0.23785 | Test loss: 0.23436, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 550 \n",
      "Train loss: 0.25498 | Test loss: 0.22818, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 560 \n",
      "Train loss: 0.25508 | Test loss: 0.21692, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 570 \n",
      "Train loss: 0.25162 | Test loss: 0.22571, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 580 \n",
      "Train loss: 0.23193 | Test loss: 0.23709, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 590 \n",
      "Train loss: 0.22928 | Test loss: 0.21622, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 600 \n",
      "Train loss: 0.23898 | Test loss: 0.22813, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 610 \n",
      "Train loss: 0.25160 | Test loss: 0.20815, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 620 \n",
      "Train loss: 0.27202 | Test loss: 0.20798, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 630 \n",
      "Train loss: 0.22916 | Test loss: 0.21392, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 640 \n",
      "Train loss: 0.20676 | Test loss: 0.22492, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 650 \n",
      "Train loss: 0.23042 | Test loss: 0.21226, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 660 \n",
      "Train loss: 0.22864 | Test loss: 0.21227, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 670 \n",
      "Train loss: 0.20567 | Test loss: 0.19850, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 680 \n",
      "Train loss: 0.20876 | Test loss: 0.21290, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 690 \n",
      "Train loss: 0.20446 | Test loss: 0.19448, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 700 \n",
      "Train loss: 0.22445 | Test loss: 0.21273, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 710 \n",
      "Train loss: 0.22234 | Test loss: 0.20165, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 720 \n",
      "Train loss: 0.21989 | Test loss: 0.20591, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 730 \n",
      "Train loss: 0.21620 | Test loss: 0.20608, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 740 \n",
      "Train loss: 0.21721 | Test loss: 0.19809, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 750 \n",
      "Train loss: 0.20144 | Test loss: 0.19240, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 760 \n",
      "Train loss: 0.20938 | Test loss: 0.19213, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 770 \n",
      "Train loss: 0.19775 | Test loss: 0.19749, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 780 \n",
      "Train loss: 0.18142 | Test loss: 0.18818, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 790 \n",
      "Train loss: 0.21643 | Test loss: 0.19360, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 800 \n",
      "Train loss: 0.19074 | Test loss: 0.19521, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 810 \n",
      "Train loss: 0.22922 | Test loss: 0.19599, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 820 \n",
      "Train loss: 0.22461 | Test loss: 0.19564, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 830 \n",
      "Train loss: 0.18642 | Test loss: 0.19843, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 840 \n",
      "Train loss: 0.24166 | Test loss: 0.18372, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 850 \n",
      "Train loss: 0.18015 | Test loss: 0.19511, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 860 \n",
      "Train loss: 0.17960 | Test loss: 0.19596, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 870 \n",
      "Train loss: 0.17224 | Test loss: 0.19241, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 880 \n",
      "Train loss: 0.17035 | Test loss: 0.18852, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 890 \n",
      "Train loss: 0.17458 | Test loss: 0.16462, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 900 \n",
      "Train loss: 0.15646 | Test loss: 0.18418, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 910 \n",
      "Train loss: 0.20209 | Test loss: 0.16491, Test acc: 100.00%\n",
      "\n",
      "EPOCH: 920 \n",
      "Train loss: 0.19628 | Test loss: 0.17237, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 930 \n",
      "Train loss: 0.18936 | Test loss: 0.18304, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 940 \n",
      "Train loss: 0.17937 | Test loss: 0.17875, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 950 \n",
      "Train loss: 0.15453 | Test loss: 0.18475, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 960 \n",
      "Train loss: 0.20662 | Test loss: 0.18791, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 970 \n",
      "Train loss: 0.19036 | Test loss: 0.17624, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 980 \n",
      "Train loss: 0.16608 | Test loss: 0.17572, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 990 \n",
      "Train loss: 0.17830 | Test loss: 0.18082, Test acc: 98.21%\n",
      "\n",
      "EPOCH: 999 \n",
      "Train loss: 0.17322 | Test loss: 0.15099, Test acc: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(iris_model.parameters(), lr=0.001)\n",
    "# accuracy = Accuracy(task=\"multiclass\", num_classes=len(train_data.classes))\n",
    "cross_entropy_loss = nn.CrossEntropyLoss() \n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "records = train_test_process(iris_model, train_dataloader, test_dataloader, optimizer, cross_entropy_loss, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e75db966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAEvCAYAAADfBqG/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2NklEQVR4nO3df4xc5Z3n+8+3291p28HGNMawbtw2GyuDA4xhW54ks5vZgZmsyaBhBmkJiWbZS8hlEwXCLHe0ykQjra40VyLSCo3ZsINQwu6inQ1hkyELI5ZkZO8uu9JM4nawHYzh2hc8pjFpO22Htqvprq6q7/2j6rRPnz6n6lTVqap2n/dLsrrqnOc8z/f5cbq6v+6qx9xdAAAAAAAAyKe+XgcAAAAAAACA3iE5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAObaq1wHEufLKK33r1q29DgMAAAAAAGDFOHDgwC/cfWP0+LJMDm3dulXj4+O9DgMAAAAAAGDFMLO/izvO28oAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHFvVqICZPS3pDkmn3f2GmPMmaY+kz0iakfR/uPtPa+d21871S/qWuz+aYewAQioV14mpgianZ7Vp3ZC2Dq9VX581VbaZOroRJy4dWc5rFnUtt3g62V63x6tT45Gm3qzbjta3ZcManTw303b9y33NdNJyu39b0el1tnV4rSTpxFRBU4U5Dfb3qViuaLC/TzPFcs/nsFm9nq9mY6g3H53uQzfHajnMSxZa6UezryfXrB9SuSKdPh9fvlJxnTxb0OT0nArFkkavWKttV3b+tblePd18LZaS749WxqbbGo1Vu+dXkobJIUn/QdI3JT2TcP52Sdtr/35N0p9L+jUz65f0hKTfljQhab+ZveDur7cbNIDFKhXXy0d+rkeeO6jZ+YqGBvr02N07tftjV8e+GMaV/fT1m/Sjo5Op6uhGnLh0ZDmvWdS13OLpZHvdHq9OjUeaerNuO1rf6PBqPXTrdv3JD15rq/7lvmY6abndv63o9DobGujTNz9/s4ol1zdePqrPjm3Rd8dP6rNjW/T4vmM9n8Nm9Xq+mo2h3nx0ug/dHKvlMC9ZaKUfzb6ebFgzqHs/Mao9e+Pvv0rFte/NSR2bvJBYJou4m+lLp35mb/b+kNT02HRbo7lo9/xK0/BtZe7+iqSzdYrcKekZr/pbSZeb2TWSdkk67u5vuXtR0rO1sgAydmKqsPBNS5Jm5yt65LmDOjFVSF32yHvvp66jG3Hi0pHlvGZR13KLp5PtdXu8OjUeaerNuu1ofXfctHkhMdRO/ct9zXTScrt/W9HpdTY7X9Hhierr7R03bdbj+44tfF0Oc9isXs9XszHUm49O96GbY7Uc5iULrfSj2deTu24ZWUhsxJU/MVXQ4Yn365bJIu5m6unUz+zN3h+tjE23NZqLds+vNFl85tBmSe+Enk/UjiUdj2VmD5jZuJmNnzlzJoOwgPyYnJ5d+KYVmJ2v6PT52dRl33s/fR3diBOXjiznNYu6lls8nWyv2+PVqfFIU2/WbUfrM1Mm9S/3NdNJy+3+bUWn15kkVbxaZ7Dmslp7vdDr+Wo2hnrzkeb6bsV5KbXVSa30o9nXk0b33+T0bNNrJKvx7/bP7M3eH62MTbc1mot2z680WSSH4v6eyuscj+XuT7n7mLuPbdy4MYOwgPzYtG5IQwOLb+ehgT5dddlQ6rLXrF+duo5uxIlLR5bzmkVdyy2eTrbX7fHq1HikqTfrtpPqa7f+5b5mOmm53b+t6MY667eLay36NYs2u6nX89VsDI3mo9H13YrzUmqrk1rpRyuvJ/XKb1o31PQayWr8u/0ze7P3Rytj022N5qLd8ytNFsmhCUnXhp6PSDpV5ziAjG0dXqvH7t656IfMx+7eufAhcmnKfuyadanr6EacuHRkOa9Z1LXc4ulke90er06NR5p6s247Wt+Lh97Vn/7eDW3Xv9zXTCctt/u3FZ1eZ0MDfbpxZL0eu3unXjz0rr566/aFr8thDpvV6/lqNoZ689HpPnRzrJbDvGShlX40+3ry/QMTevi25Ptv6/Ba3Tiyvm6ZLOJupp5O/cze7P3Ryth0W6O5aPf8SmPuiX/Mc7GQ2VZJf5WwW9nvSHpQ1d3Kfk3S4+6+y8xWSfp/Jd0m6V1J+yV93t2PNGpvbGzMx8fHm+kHkHvBJ+mfPj+rqy5Lt1NHtGwzdXQjTlw6spzXLOpabvF0sr1uj1enxiNNvVm3Ha0v2K2s3fqX+5rppOV2/7ai0+ssvPvP2cKcBlbIbmW9XH/tfg+T1JU+dHOslsO8ZKGVfjT7enL1uupuZWcuxJcP78g1UyxpSxO7lXXq9aSbr8VS8v3Ryth0W6Oxavf8pcjMDrj72JLjjZJDZvYdSf9Y0pWSJiX9a0kDkuTuT9a2sv+mpN2qbmV/n7uP1679jKQ/U3Ur+6fd/f9JEyzJIQAAAAAAgGwlJYcabmXv7p9rcN4lfSXh3EuSXkobJAAAAAAAALori88cAgAAAAAAwCWK5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxkkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHIsVXLIzHab2ZtmdtzMvhZzfoOZPW9mh83sJ2Z2Q+jcw2b2mpkdMbM/zDB2AAAAAAAAtKlhcsjM+iU9Iel2STskfc7MdkSKfV3SQXe/SdK9kvbUrr1B0v8paZekX5V0h5ltzy58AAAAAAAAtCPNXw7tknTc3d9y96KkZyXdGSmzQ9JeSXL3NyRtNbNNkq6X9LfuPuPuJUn/U9LvZxY9AAAAAAAA2pImObRZ0juh5xO1Y2GHJN0lSWa2S9KopBFJr0n6lJkNm9kaSZ+RdG27QQMAAAAAACAbq1KUsZhjHnn+qKQ9ZnZQ0s8kvSqp5O5Hzewbkv5a0gVVk0il2EbMHpD0gCRt2bIlVfAAAAAAAABoT5q/HJrQ4r/2GZF0KlzA3afd/T5336nqZw5tlPR27dy33f0Wd/+UpLOSjsU14u5PufuYu49t3Lix+Z4AAAAAAACgaWmSQ/slbTezbWY2KOkeSS+EC5jZ5bVzkvRFSa+4+3Tt3FW1r1tUfevZd7IKHgAAAAAAAO1p+LYydy+Z2YOSfiipX9LT7n7EzL5UO/+kqh88/YyZlSW9Lun+UBXfN7NhSfOSvuLu57LuBAAAAAAAAFqT5jOH5O4vSXopcuzJ0OO/kRS7Rb27/6N2AgQAAAAAAEDnpHlbGQAAAAAAAFYokkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOUZyCAAAAAAAIMdW9TqAlahScZ2YKmhyelab1g1p6/BaSVpyrK/Pehxp9ioV18mzBU1Oz6lQLGn0irXadmVzfQ3XUSyXte5DA5qZL3dk3OLmKq7+NP0KykxdKGq2VNbcfEWjw9Vy0tL5D45NFea0eqBfhbly2/1NWntBXCWvSJJKZVel4lo3FN9Wvb709VnqcQvHFO3nhtWDKhTLi8YzbpyS5iNcbsuGNTp5bkaT07O6Zv2Q3KXT56tztW14rSounT5fPVeuVB+H6w/HONjfp5liOfZ8UH+5Ip2dqfZnbr6ikldUKrvm5isL/ThbuDjerQjqGx1eq9Erqv0LxjBoM67cxC9nlsx1XFzh64Jz0XXSbLyVimvDmsXzGhdTvWvnShXNlsqL6grWy1ypkjq2aJ3tzkW0rui4hteb1N78h+/PYqWiwf4+FcuVJXOfZV+bqSPLsU1bb3RMksai3TbDay+pb2n634kxSjM+Wc9J1nG2Ukf0e0CaOWo39k6vs+B7SDP3eaP6eqkX8bRy79aLt1t96PRrU6fa6qVW+tns9+lGP2u08jNeVuOfVE8z8bfbXqPXnyx//s0y7jTn0p6P/i60Upm79zqGJcbGxnx8fLzXYbSkUnG9fOTneuS5g5qdr2hooE/f/PzNKpZ80bHH7t6p3R+7ekUtrkrFte/NSR2bvKA9e4+11NdwHc/uP6nPjm3R4/taqytNW9G5iqs/Tb+CMqfOfaBCsbyoXNz8B8e+8fJRfeGT2zQzX267v0lrT5JOnftgoVyhWL8tSYl9eezunfr09Zv0o6OTqdZzEFO0n8HjRuOUNB/hfo4Or9ZDt27Xn/zgNW1YM6gv/8Z1C3FvWDOoez8xuuRxXH++8fLR2DEJ9zeoI+iD2cUxDdr48m9c1/KaDM9REGfQv3+779iiNuPK/dGnP6pzheKS89G44tZodJ00G2/cvMbFVO9as6V1Rce62XiauS5tXdFxzXL+w/fnd8cvfk3qSxZ9baaOLMc2bb3RMcmq7XprL6n+rMq0G2un22tV1usx+j2gk33t1jqLa6uZNpfTfPcqnlbu3XrxdqsPnX5t6lRbvdRKP5v9Pt3oZ41WXuOzGv+kerL4WSlte41ef7L8+bdV7bxGpjnf6u+1y5mZHXD3sSXHSQ5l660zF/SZx/+XZucvZhy/ettH9NQrby06NjTQp5e++o903cYP9yLMjnjrzAX94OC7bfU1XMf9//A6fft/d27c4uYqrv40/QrKSFpSLm7+g2P3/8Pr1N+nTPqbtPaiGrUlKbEvQwN9+u4DH9dnn/rbVHEGMUX7GTxu5T6J9vMrv/mRhb585Tc/sqju6Lm4Pgf9SRqTcH+DOoI+hMc03H67wuOQ1GZcuaTz0XNxY99uvHHzmmY8wtfG1RXX72biaVdcXdFxzXL+w/dn+GtSvVn0tZk6shzbtPVGxySrtuutvVbibKZMu7F2ur1WZb0eW5mjdtvt9DqLa6uZNpfTfEu9iaeddVFvPjrdh06/NnWqrV5qpZ/Nfp9O00azr/FZjX9SPVn8rJS2vUavP1n+/Nuqdl4j085/YKX8Dp+UHOJtZRmbnJ5dtIAkqeJacmx2vqLT52cv+YUVNjk923Zfw3WYdXbc4uYqrv40/QrKBMfD4q4N9zGr/iatvahGbbkrsS+z8xW99366cQvHFO1nvTFpVG+0n+G+ROuOnqvXn0bnw3UE7YTLhdtvV1z/4uqOlks6nxRvoN2Yk+Y1zXhE+5a0XlqNp11p5jvL+Q+vxXpzXy++VttMU0eWY5u23rRj0W6baerPqky7sXa6vVZlvR5bmaN22+30Ootrazncg63qRTztrIt689HpPnT6talTbfVSK/1s9vt0mjak5l7jsxr/ej//tfuzUtr2Gr3+SNn9/Nuqdl4j085/+PlK+x0+jORQxjatG9LQQN+ihdRvWnJsaKBPV1021IsQO2bTuqG2+xquI7i2U+MWN1dx9afpV1AmLua4a8N9zKq/SWsvKk1bSX0ZGujTNetXp44ziCmpz63cJ0nzFjyP1pP0ONqftP0N9yGp/XbFxRFXd6P5ToorzTppNt6gnmbrjvYtab20Gk+70sx3lvMfXotJ7TeKr9U209SR5dimrTftWLTbZpr6syrTrDTjk/WctCLr9djKHLXbbqfXWVxby+EebFUv4mlnXdSbj073odOvTZ1qq5da6Wez36fTtNHsa3xW41/v57/geDd+5kmqP+uff1vVzmtkM/MfPF9pv8OH8bayjPGZQ3zmEJ85tDQmPnOoOXzmEJ85xGcOLT3HZw7xmUN85tDymu9excNnDvGZQ/XO85lD2bbHZw7xmUM9dyknh6SLOymdPj+rqy5bvDNV+NilvqjihHf1mimWtKXN3crmy2Vd1oXdyhrNS5p+RXf4KpYqC+WkpfMfHDtbmNNQbRevdvubtPbiditz98S26vUlvHtXmvUclI328/LabmXh8Ywbp3q7lQXlgt3KTp+f1dXrLu5WNlMsaWttt7IzF6rnypXq43D94RgH6uxWFtRfrkjnZqr9Ce9WVixVFsY8i93KgnEPdisLxjC6W1m4XNxuZXFxha/Larcyd18yr2l3KwuuDXadCdcVrJdmdysL19nuXETrio5reL1J7e9WFtyfaXcra7evzdSR5dimrTc6JlnuIpW09urtcJNFmXZjjRufrOck6zhbqSP6PSDNHLUbe6fXWfA9pJn7vFF9vdSLeFq5d+vF260+dPq1qVNt9VIr/Wz2+3SjnzVa+Rkvq/FPqqeZ+Nttr9HrT5Y//2YZd5pzac9Hfxe61LWVHDKz3ZL2SOqX9C13fzRyfoOkpyX9fUmzkr7g7q/Vzv1LSV+U5JJ+Juk+d5+t196lnhwCAAAAAABYbpKSQw0/V9zM+iU9Iel2STskfc7MdkSKfV3SQXe/SdK9qiaSZGabJX1V0pi736BqcumedjoCAAAAAACA7KTZdG6XpOPu/pa7FyU9K+nOSJkdkvZKkru/IWmrmW2qnVslabWZrZK0RtKpTCIHAAAAAABA29IkhzZLeif0fKJ2LOyQpLskycx2SRqVNOLu70r6N5JOSnpP0vvu/qN2gwYAAAAAAEA20iSH4j5xKfpBRY9K2mBmByU9JOlVSaXaZxHdKWmbpL8naa2Z/UFsI2YPmNm4mY2fOXMmbfwAAAAAAABoQ5rk0ISka0PPRxR5a5i7T7v7fe6+U9XPHNoo6W1JvyXpbXc/4+7zkv5S0ifjGnH3p9x9zN3HNm7c2HxPAAAAAAAA0LQ0yaH9krab2TYzG1T1A6VfCBcws8tr56TqzmSvuPu0qm8n+7iZrTEzk3SbpKPZhQ8AAAAAAIB2rGpUwN1LZvagpB+qutvY0+5+xMy+VDv/pKTrJT1jZmVJr0u6v3bux2b2PUk/lVRS9e1mT3WkJwAAAAAAAGiauUc/Pqj3xsbGfHx8vNdhAAAAAAAArBhmdsDdx6LH07ytDAAAAAAAACsUySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxkkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAORYquSQme02szfN7LiZfS3m/AYze97MDpvZT8zshtrxj5rZwdC/aTP7w4z7AAAAAAAAgBatalTAzPolPSHptyVNSNpvZi+4++uhYl+XdNDdf9/MfqVW/jZ3f1PSzlA970p6PtsuAAAAAAAAoFVp/nJol6Tj7v6WuxclPSvpzkiZHZL2SpK7vyFpq5ltipS5TdL/5+5/12bMAAAAAAAAyEia5NBmSe+Enk/UjoUdknSXJJnZLkmjkkYiZe6R9J3WwgQAAAAAAEAnpEkOWcwxjzx/VNIGMzso6SFJr0oqLVRgNijpdyX9l8RGzB4ws3EzGz9z5kyKsAAAAAAAANCuhp85pOpfCl0bej4i6VS4gLtPS7pPkszMJL1d+xe4XdJP3X0yqRF3f0rSU5I0NjYWTT4BAAAAAACgA9L85dB+SdvNbFvtL4DukfRCuICZXV47J0lflPRKLWEU+Jx4SxkAAAAAAMCy0/Avh9y9ZGYPSvqhpH5JT7v7ETP7Uu38k5Kul/SMmZUlvS7p/uB6M1uj6k5n/6ID8QMAAAAAAKANad5WJnd/SdJLkWNPhh7/jaTtCdfOSBpuI0YAAAAAAAB0SJq3lQEAAAAAAGCFIjkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxkkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjq3qdQB5VKm4TkwVNDk9q03rhrR1eK36+iz1+TTl0tTRahxp44vWM1WY02B/n4rligb7+zRTLC9cL2lJnc0emyrMafVAvwpzZRWKJY1esVbbrkzXb0k6ebagqQtFzZbKmpuvaHR46fWViuvk2YImp+cWtRGNa8uGNZr45YymLhRV8opKZVel4tqwZlCFYlnFclnrPjSgYuXiWFyzfkjlinT6/KyuWT8kd+n0+YvtjF6xtM65+Yq2XblWFa9eF+1PNM64sQj6HY5z3dCAZubLi/oS1LVtuNre2ZmL4x3uz+qBfs3NV1TyiiTF1hleS/XaD8Yk3FbceMyWyovGN4hTqo5hsVzWhtUXx37D6kHNlSoL160bujgXxfLiPgTjPDpcbfPkuZmFtRxdw2nGvBnh9RaMcdwYhu+vcEzhMY5bs9GxT1r3rcbd6H4Kl2/me8pyEB3X8HrLcv4vtXHJA+alu7o53swtACDPSA51WaXievnIz/XIcwc1O1/R0ECfHrt7p3Z/7OqFX+TqnU9Tj6SGdbQax6ev36QfHZ1sGF80zm+8fFSfHdui746f1GfHtujxfccWrv/m529WseSL6mz22DdePqovfHKbZubL2rP3WFP9/ubnb5YknTr3gQrF5OsrFde+Nyd1bPLCojLRuEaHV+uPPv1RnSsUJUmFYlnP7j9Zi29az+4/uWQsNqwZ1L2fGNWevdXHX/6N6xbFEldnUDa4LtqfaJxxY7HvzUmdOvfBojjD8xO0O3Hug0XtXexPeVF/vvDJbbLQMoirM7yW/sex04ntx7UVNx7R8Y2OYXTsqzEWFrUXzEW0D9E5eOjW7fq3+47FruE0Y97s94pgvdUbwx8dnVy4v5LGOG7NBms+2s+s4m50P4XLp/met5xEvxfE3bNZjOOlNi55wLx0VzfHm7kFAOQdbyvrshNThYUfPCRpdr6iR547qBNThVTn09STpo5W4zjy3vup4ou2c8dNm/X4vmMLX8PXH55YWmezx+64abOmZooLv5g10+/DE+/r8MT7+kWh/vUnpgo6PPH+kjLRuO64abOOnb6gXxSKC3WG44sbi7tuGVmo965bRpbEEldn9Lpof9KMRdDvcJzh+QnajbaX1J+pmeJCfUl1htdSvfbj2oobj7gy4TGMxhrEGDcX0T5E2/yTH7yWuIbTjHkzwuut3hiG76+kMU5aI3H9zCrutPWm/Z63nES/F8Tds1mM46U2LnnAvHRXN8ebuQUA5B3JoS6bnJ5d+MEjMDtf0enzs6nOp6knTR2txvHe++nii7ZjpkVfwyre/jGz+PNp+l3xi/8ajUmauIJYwnWG44sbi+jjNHVGr4v2J81YxMUZ1260vaT+hOtLqjOI5b3367cf11bceMSVicYXfZw0F0njHI2n1TFvRni91RvDNGNcb813Ku609ab9nrecRL8XpP3+02wbl9q45AHz0l3dHG/mFgCQdySHumzTuiENDSwe9qGBPl112VCq82nqSVNHq3Fcs351qvji2ol+DfRbNsfizqfpd79d/NdoTJqJK1pn+HHcWIQfp60zel24XJqxiKuzUf/q9SdcX706g7XUqGy9ua03vtHn0cf15qLRekgaozRj3ozoemt0P9Yb43prqVNxp6037fe85STue0EnxvFSG5c8YF66q5vjzdwCAPKO5FCXbR1eq8fu3rnoF7rH7t658IG2jc6nqSdNHa3G8bFr1qWKL9rOi4fe1Vdv3b7wNXz9jSPrl9TZ7LEXD72rK9YM6uHbtjfd7xtH1uvGkfUaXlv/+q3Da3XjyPolZaJxvXjoXX3kqg9reO3gQp3h+OLG4vsHJhbq/f6BiSWxxNUZvS7anzRjEfQ7HGd4foJ2o+0l9eeKNYML9SXVGV5L9dqPaytuPOLKhMcwGmsQY9xcRPsQbfNPf++GxDWcZsybEV5v9cYwfH8ljXHSGonrZ1Zxp6037fe85ST6vSDuns1iHC+1cckD5qW7ujnezC0AIO/M3XsdwxJjY2M+Pj7e6zA6JtgN4/T5WV11WfIuYUnn05RLU0ercaSNL1rP2cKcBhrsVhaus9ljZwtzGqrtaDVTLGlLg93KonWEd1cqliqx14d3KAq3EY0rbrcyd9fltR2z5stlXZawW9mZC7O6et3F3cqCduJ2KyuWKtpa2z3szIWl/YnGmWa3MnfXZR+K361splhaaO/czMXxDvcnbreyaJ31disLlw3GJNxW3HjMlsqLxjeIU6qO4Xy5vGjsLw/tVha0V2+3smA9BLuVBWs5abeyemPejPB6C8Y4abeyuJiiu5VF12x07JPWfatxN7qfwuWb+Z6yHETHNbzespz/S21c8oB56a5ujjdzCwDIAzM74O5jS46THAIAAAAAAFj5kpJDvK0MAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjqVKDpnZbjN708yOm9nXYs5vMLPnzeywmf3EzG4InbvczL5nZm+Y2VEz+0SWHQAAAAAAAEDrGiaHzKxf0hOSbpe0Q9LnzGxHpNjXJR1095sk3StpT+jcHkkvu/uvSPpVSUezCBwAAAAAAADtS/OXQ7skHXf3t9y9KOlZSXdGyuyQtFeS3P0NSVvNbJOZrZP0KUnfrp0ruvsvswoeAAAAAAAA7UmTHNos6Z3Q84nasbBDku6SJDPbJWlU0oik6ySdkfTvzexVM/uWma1tO2oAAAAAAABkIk1yyGKOeeT5o5I2mNlBSQ9JelVSSdIqSbdI+nN3v1lSQdKSzyySJDN7wMzGzWz8zJkzKcMHAAAAAABAO9IkhyYkXRt6PiLpVLiAu0+7+33uvlPVzxzaKOnt2rUT7v7jWtHvqZosWsLdn3L3MXcf27hxY3O9AAAAAAAAQEvSJIf2S9puZtvMbFDSPZJeCBeo7Ug2WHv6RUmv1BJGP5f0jpl9tHbuNkmvZxQ7AAAAAAAA2rSqUQF3L5nZg5J+KKlf0tPufsTMvlQ7/6Sk6yU9Y2ZlVZM/94eqeEjSX9SSR29Jui/jPgAAAAAAAKBF5h79+KDeGxsb8/Hx8V6HAQAAAAAAsGKY2QF3H4seT/O2MgAAAAAAAKxQJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxkkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByLFVyyMx2m9mbZnbczL4Wc36DmT1vZofN7CdmdkPo3Akz+5mZHTSz8SyDBwAAAAAAQHtWNSpgZv2SnpD025ImJO03sxfc/fVQsa9LOujuv29mv1Irf1vo/G+6+y8yjBsAAAAAAAAZSPOXQ7skHXf3t9y9KOlZSXdGyuyQtFeS3P0NSVvNbFOmkQIAAAAAACBzaZJDmyW9E3o+UTsWdkjSXZJkZrskjUoaqZ1zST8yswNm9kBSI2b2gJmNm9n4mTNn0sYPAAAAAACANqRJDlnMMY88f1TSBjM7KOkhSa9KKtXO/bq73yLpdklfMbNPxTXi7k+5+5i7j23cuDFV8AAAAAAAAGhPw88cUvUvha4NPR+RdCpcwN2nJd0nSWZmkt6u/ZO7n6p9PW1mz6v6NrVX2o4cAAAAAAAAbUvzl0P7JW03s21mNijpHkkvhAuY2eW1c5L0RUmvuPu0ma01s8tqZdZK+rSk17ILHwAAAAAAAO1o+JdD7l4yswcl/VBSv6Sn3f2ImX2pdv5JSddLesbMypJel3R/7fJNkp6v/jGRVkn6z+7+cvbdAAAAAAAAQCvMPfrxQb03Njbm4+PjvQ4DAAAAAABgxTCzA+4+Fj2e5m1lAAAAAAAAWKFIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYw13K0NrKhXXiamCJqdndc36IZUr0tmZOa0e6Fdhrqxiuax1HxrQzHxZm9YNaevwWvX1WWw9J88WNHWhqJJXFo6Xyq65+Yq2XblWFa/WPdjfp5lieUl7c/MVlbyy6BpJOn1+ToViSduGq8/PFpa2Uam41g1V47xm/ZDcq9cVy2VtWD2ouVIlMa6gztlSeaGeYqWiwf4+FcuVxNgqLp0+P7swLpJ08mxBk9Px8cbFWa7E1zF14WI8G9YMqlBcOhdbNqzRxC9nFo15EN/o8NqFvoXnJXo+bi7j1ka9uY/O/2ypHBvD5PTcoj6E+x83FvViqyeIJZiH0SsuxnFiqqCpwsU12G5bQXvResNrMBxDO31qNBdxcWTRvyw1s6YAAAAAIIrkUAdUKq6Xj/xcjzx3UBvWDOreT4zq2f0n9YVPbtPMfFnP7j+pz45t0eP7jml2vqKhgT49dvdO7f7Y1Yt+oatUXPvenNSpcx8sqr9QLGvP3mOL6g7qi7ZntvSaL//GdUueRxWK5SX1BtddrLuQGFdQZ7ie745f/JoU272fGNWevRfH5Zufv1mSdGzyQmy8cXEm1XHq3AeL4p+Zn14yF6PDq/VHn/6ozhWKS/oVV1/c+bi5jFsbjcqH5z8phmOTFxL7HzcW9WKrJ4glmIdwHMWS6xsvH021pptp7+UjP19Ub3TtZtGnRnMRF0cW/ctSM2sKAAAAAOLwtrIOODFVWPhF7a5bRrRn7zHdcdNmTc0UFx4Hv2RK0ux8RY88d1AnpgpL6jk88b5+USgu+hf8YhyuO6gv2l7cNXHP49qI1hs+Hq47qY1oPeGvSbEFj4NxOTzxvg5PvJ8Yb1L/4+qIxh83F3fctFnHTl+I7VdcfXHn4+Yybm00Kh+e/3rjktT/uLGoF1ujNR2eh3Acjzx3MPWabqa9aL3RtZtFnxrNRVwcWfQvS82sKQAAAACIQ3KoAyanZxd+UTOr/rJmJlX84uPgfGB2vqLT52eX1FNxLfkXV3dSe3HXxD2PayNab/h4o7ji6kkTW3Rc6tWdFGdSHdH44+Yirm/16os7HzeXcWujUfnw/Ncbl6T+p11naQSxxMXRzJpupr16azCLdtLMRVwc7babtWbWFAAAAADEITnUAZvWDWlo4OLQBo/77eLj8Png+VWXDS2pp9+05F9c3UntxV0T9zypjaTrGsWVVE+j2KLjUq/upDiT6ojGnzQX9fqV5nzcXAaia6Ne+fD8NxqXpP43E1s9QSxxcTSzpptpr9EabLedNHORFEc77WatmTUFAAAAAHFIDnXA1uG1euzunRoa6NP3D0zo4du268VD7+qKNYMLj7966/ZFv3Q+dvfOhQ9ODtdz48h6Da8dXPTv4du2L6k7qC/aXtw1cc/j2ojWGz4erjupjWg94a9JsQWPg3G5cWS9bhxZnxhvUv/j6ojGHzcXLx56Vx+56sOx/YqrL+583FzGrY1G5cPzX29ckvofNxb1Ymu0psPzEI7jsbt3pl7TzbQXrTe6drPoU6O5iIsji/5lqZk1BQAAAABxzN17HcMSY2NjPj4+3usw2hLsHnT6/KyuXlfdMerczJyGaruVzZfLuqzN3cqKpYq2Dld39zo3M6eByG5lQXvhHcGCa6Tqjk8zxdLC87jdytx9Ic7wTlHz5bIuT9itLNxGsFtZUE+93crC/TlzYVZXXbZ0t7K4eOPiLFfi6wh2/XJ3Xb66ultZdC6SdisrlirackXybmXh82l2Kzt9/mJ8aXcri4thcnpuUR/C/Q/WXngsstitbKZYWhTHiamCzhYursEsdysL1xteg+EY2t2trN5cxMWx3HYEa2ZNAQAAAMgvMzvg7mNLjpMcAgAAAAAAWPmSkkO8rQwAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcixVcsjMdpvZm2Z23My+FnN+g5k9b2aHzewnZnZD5Hy/mb1qZn+VVeAAAAAAAABoX8PkkJn1S3pC0u2Sdkj6nJntiBT7uqSD7n6TpHsl7Ymcf1jS0fbDBQAAAAAAQJbS/OXQLknH3f0tdy9KelbSnZEyOyTtlSR3f0PSVjPbJElmNiLpdyR9K7OoAQAAAAAAkIk0yaHNkt4JPZ+oHQs7JOkuSTKzXZJGJY3Uzv2ZpH8lqdJOoAAAAAAAAMhemuSQxRzzyPNHJW0ws4OSHpL0qqSSmd0h6bS7H2jYiNkDZjZuZuNnzpxJERYAAAAAAADatSpFmQlJ14aej0g6FS7g7tOS7pMkMzNJb9f+3SPpd83sM5KGJK0zs//k7n8QbcTdn5L0lCSNjY1Fk08AAAAAAADogDR/ObRf0nYz22Zmg6omfF4IFzCzy2vnJOmLkl5x92l3/2N3H3H3rbXr9sUlhgAAAAAAANAbDf9yyN1LZvagpB9K6pf0tLsfMbMv1c4/Kel6Sc+YWVnS65Lu72DMAAAAAAAAyIi5L793cI2Njfn4+HivwwAAAAAAAFgxzOyAu49Fj6d5WxkAAAAAAABWKJJDAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxkkMAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyDGSQwAAAAAAADlGcggAAAAAACDHSA4BAAAAAADkGMkhAAAAAACAHCM5BAAAAAAAkGMkhwAAAAAAAHKM5BAAAAAAAECOkRwCAAAAAADIMZJDAAAAAAAAOZYqOWRmu83sTTM7bmZfizm/wcyeN7PDZvYTM7uhdnyo9vyQmR0xs/876w4AAAAAAACgdQ2TQ2bWL+kJSbdL2iHpc2a2I1Ls65IOuvtNku6VtKd2fE7Sre7+q5J2StptZh/PKHYAAAAAAAC0Kc1fDu2SdNzd33L3oqRnJd0ZKbND0l5Jcvc3JG01s01edaFWZqD2z7MJHQAAAAAAAO1KkxzaLOmd0POJ2rGwQ5LukiQz2yVpVNJI7Xm/mR2UdFrSX7v7j9uMGQAAAAAAABlJkxyymGPRv/55VNKGWhLoIUmvSipJkruX3X2nqsmiXcHnES1pxOwBMxs3s/EzZ86kDB8AAAAAAADtWJWizISka0PPRySdChdw92lJ90mSmZmkt2v/wmV+aWb/Q9JuSa9FG3H3pyQ9JUljY2Mr4q1nlYrr5NmCJqfnVCiWNHrFWm27cq36+mzR+akLRc2WyqpUXBvWDKpQLKtYLmvD6urjpGtPTBU0OT2ra9YPqVyRzs7MafVAvwpzyddE4xm9Yo1OnpvR5PSsNq0b0tbhi+XT9qOb4xn0OSnWaMxTF4oqeUWlsmtuvqLR4d7EDgAAAADAcpUmObRf0nYz2ybpXUn3SPp8uICZXS5ppvaZRF+U9Iq7T5vZRknztcTQakm/JekbWXZguapUXPvenNSxyQvas/eYZucrGhro02N379Tuj10tSdr35qROnftAhWJZz+4/qS98cptm5qcXPU669uUjP9cjzx3UhjWDuvcTo6FrynXbC8czOrxaD926XX/yg9eWlA8nlOr1o1tJlkrFF/rcKIYg5lPnPpAkFYrxY0KCCAAAAACAFG8rc/eSpAcl/VDSUUnPufsRM/uSmX2pVux6SUfM7A1VdzV7uHb8Gkn/3cwOq5pk+mt3/6usO7EcnZgq6PDE+wtJCUmana/okecO6sRUYeH8LwpF7dl7THfctFlTM0sfJ10bJEnuumUk9TXReO64afNCYihaPm0/ujmeQZ8bxRAe22B8exk7AAAAAADLWZq/HJK7vyTppcixJ0OP/0bS9pjrDku6uc0YL0mT07OquBaSEoHZ+YpOn5+Vu1Txi8fMtFA+/Djp2uCcWfproueDa+PKX7fxw6n6EZTrtMnp2dQxBDGHy6W5DgAAAACAPEqVHELzNq0bUr9JQwN9i5ITQwN9uuqyIUlSv108FjyPPk66Nnwu7TVJ55PKp+1HN2xaN5Q6hiDmcLlexg4AAAAAwHKWZrcytGDr8FrdOLJeD9+2fSF5E3zezdbhtQvnh9cO6uHbtuvFQ+/qijVLHydd+9jdOzU00KfvH5hIfU00nhcPvas//b0bYsun7Uc3xzPoc6MYwmMbjG8vYwcAAAAAYDkz9+W3MdjY2JiPj4/3Ooy2hXf5mimWtKXBbmXurstrO5TNl8sLj5OuPTFV0Onzs7p6XXW3snMzcxqq7VZWr71wPMFuZafPz+qqyxrvVhZXbzfHM+hzUqzRmMO7lRVLlZ7FDgAAAABAr5nZAXcfW3Kc5BAAAAAAAMDKl5Qc4m1lAAAAAAAAOUZyCAAAAAAAIMdIDgEAAAAAAOQYySEAAAAAAIAcIzkEAAAAAACQYySHAAAAAAAAcozkEAAAAAAAQI6RHAIAAAAAAMgxc/dex7CEmZ2R9He9jiMDV0r6Ra+DAC4B3CtAetwvQDrcK0A63CtAOivlXhl1943Rg8syObRSmNm4u4/1Og5gueNeAdLjfgHS4V4B0uFeAdJZ6fcKbysDAAAAAADIMZJDAAAAAAAAOUZyqLOe6nUAwCWCewVIj/sFSId7BUiHewVIZ0XfK3zmEAAAAAAAQI7xl0MAAAAAAAA5RnKoQ8xst5m9aWbHzexrvY4H6CUzu9bM/ruZHTWzI2b2cO34FWb212Z2rPZ1Q+iaP67dP2+a2T/pXfRAd5lZv5m9amZ/VXvOfQLEMLPLzex7ZvZG7fXlE9wvwFJm9i9rP3+9ZmbfMbMh7hVAMrOnzey0mb0WOtb0vWFm/8DMflY797iZWbf7kgWSQx1gZv2SnpB0u6Qdkj5nZjt6GxXQUyVJ/5e7Xy/p45K+UrsnviZpr7tvl7S39ly1c/dI+pik3ZL+Xe2+AvLgYUlHQ8+5T4B4eyS97O6/IulXVb1vuF+AEDPbLOmrksbc/QZJ/areC9wrgPQfVF3nYa3cG38u6QFJ22v/onVeEkgOdcYuScfd/S13L0p6VtKdPY4J6Bl3f8/df1p7fF7VH+A3q3pf/Mdasf8o6fdqj++U9Ky7z7n725KOq3pfASuamY1I+h1J3wod5j4BIsxsnaRPSfq2JLl70d1/Ke4XIM4qSavNbJWkNZJOiXsFkLu/Iuls5HBT94aZXSNpnbv/jVc/0PmZ0DWXFJJDnbFZ0juh5xO1Y0DumdlWSTdL+rGkTe7+nlRNIEm6qlaMewh59WeS/pWkSugY9wmw1HWSzkj697W3YX7LzNaK+wVYxN3flfRvJJ2U9J6k9939R+JeAZI0e29srj2OHr/kkBzqjLj3GLItHHLPzD4s6fuS/tDdp+sVjTnGPYQVzczukHTa3Q+kvSTmGPcJ8mKVpFsk/bm73yypoNqf/ifgfkEu1T4v5U5J2yT9PUlrzewP6l0Sc4x7BUi+N1bMPUNyqDMmJF0bej6i6p9vArllZgOqJob+wt3/snZ4svanmKp9PV07zj2EPPp1Sb9rZidUfTvyrWb2n8R9AsSZkDTh7j+uPf+eqski7hdgsd+S9La7n3H3eUl/KemT4l4BkjR7b0zUHkePX3JIDnXGfknbzWybmQ2q+sFVL/Q4JqBnap/Y/21JR939sdCpFyT989rjfy7pv4aO32NmHzKzbap+sNtPuhUv0Avu/sfuPuLuW1V93djn7n8g7hNgCXf/uaR3zOyjtUO3SXpd3C9A1ElJHzezNbWfx25T9bMfuVeAeE3dG7W3np03s4/X7rF7Q9dcUlb1OoCVyN1LZvagpB+quiPA0+5+pMdhAb3065L+maSfmdnB2rGvS3pU0nNmdr+qP7z8U0ly9yNm9pyqP+iXJH3F3ctdjxpYHrhPgHgPSfqL2n/EvSXpPlX/45P7Bahx9x+b2fck/VTVtf+qpKckfVjcK8g5M/uOpH8s6Uozm5D0r9Xaz11fVnXns9WS/lvt3yXHqh+oDQAAAAAAgDzibWUAAAAAAAA5RnIIAAAAAAAgx0gOAQAAAAAA5BjJIQAAAAAAgBwjOQQAAAAAAJBjJIcAAAAAAAByjOQQAAAAAABAjpEcAgAAAAAAyLH/H419ueIJIfefAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(records)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.scatterplot(x=[i for i in range(len(records))], y=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dbd1bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "predict(iris_test_dataset[1][0], iris_test_dataset[1][1], iris_model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
