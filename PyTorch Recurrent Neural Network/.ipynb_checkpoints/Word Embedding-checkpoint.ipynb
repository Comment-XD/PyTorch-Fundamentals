{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caef77d-97c0-48c6-ac59-b43b2f9b2241",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "***\n",
    "\n",
    "- Word embedding is a method used to find relations between vectors\n",
    "- Typically defined as a way to convert words to context vectors\n",
    "\n",
    "**Preprocessing**\n",
    "1. `Load in Data`\n",
    "2. `Remove Stop Words`\n",
    "3. `Convert to Bigram`\n",
    "4. `Convert Bigram to One-Hot-Encodings`\n",
    "\n",
    "**Training**\n",
    "1. `Split Bigram to Train, Test Data`\n",
    "2. `Create Linear Model`\n",
    "3. `Obtain Weights After Training`\n",
    "4. `Vizualize Points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e2064474-61c5-4c98-9bea-9ae7706449a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4d61f7c9-f951-47ec-a164-542d1f3f121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = [\"is\", \"a\", \"has\", \"an\"]\n",
    "\n",
    "    removed_stop_words_list = []\n",
    "    \n",
    "    for i, _ in enumerate(data):\n",
    "        removed_stop_words_list.append([word for word in data[i].replace(\"\\n\", \"\").split(\" \") if word not in stop_words])\n",
    "\n",
    "    return removed_stop_words_list\n",
    "                \n",
    "def bigrams(data):\n",
    "    bigram_list = []\n",
    "\n",
    "    for _, word in enumerate(data):\n",
    "        for j in range(len(word) - 1):\n",
    "            bigram_list.append([word[j], word[j+1]])\n",
    "\n",
    "    return bigram_list\n",
    "\n",
    "def vocabulary(bigram_data):\n",
    "    vocab_list = []\n",
    "    for bigram in bigram_data:\n",
    "        vocab_list.extend(bigram)\n",
    "\n",
    "    return list(set(vocab_list))\n",
    "\n",
    "def one_hot_encoder(vocab_data, bigram_data):\n",
    "    one_hot_values = {}\n",
    "    for i, key in enumerate(vocab_data):\n",
    "        one_hot_values[key] = [0 if i != j else 1 for j in range(len(vocab_data))]\n",
    "\n",
    "    for i, (X,y) in enumerate(bigram_data):\n",
    "        # print(bigram_data[i])\n",
    "        bigram_data[i][0] = one_hot_values[X]\n",
    "        bigram_data[i][1] = one_hot_values[y]\n",
    "\n",
    "    return np.array(bigram_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a45e4d-25a0-4ce6-b75c-85baec5428da",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "1. Load in Data\n",
    "   - Using a default txt file with a bunch of names and adjectives\n",
    "   - Python's **`open()`** function will open the text file\n",
    "   - **`readlines()`** function will split the text file by new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4ee40209-8c3e-4525-9061-54aa8c6e288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"text_data.txt\", \"r\")\n",
    "data = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cf882-1571-457e-8d5f-b8f6ba6f3ca3",
   "metadata": {},
   "source": [
    "2. Remove Stop Words\n",
    "   - Using our built function **`remove_stop_words()`**, it cleans the sentence (removes \"\\n\")\n",
    "   - Then, removes stop words (\"is\", \"a\", \"an\", \"has\") from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42e39f1b-5e16-42ab-a773-82eaa4d71c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = remove_stop_words(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06f4b6-8ad5-469f-8302-ff16bdfcfcd6",
   "metadata": {},
   "source": [
    "3. Bigrams\n",
    "   - Using our built function **`bigrams()`**, it converts our newly cleaned txt_data to bigrams\n",
    "   - We will use sliding window technique to get all the bigrams\n",
    "   <br></br>\n",
    "  \n",
    "**What is Bigrams**\n",
    "- A sequence of two words, the first value being the feature and the seconds value being the label\n",
    "- Example: \"I am great\" will become (\"I\", \"am\") and (\"am great\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44586499-2bcd-43eb-9592-e7f65a7c9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_data = bigrams(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b67533-e4fa-4d25-8d38-2d93c8ee9faa",
   "metadata": {},
   "source": [
    "4. Convert Bigrams to One-Hot-Encodings\n",
    "   - Using our built function **`one_hot_encoder()`**, it cleans the sentence (removes \"\\n\")\n",
    "   - Then, removes stop words (\"is\", \"a\", \"an\", \"has\") from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a989024-18ef-4ed2-ae16-9235497596f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = one_hot_encoder(vocab_data, bigram_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "22acc264-ee4f-45e4-b5c6-4f76b32f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[:, 0]\n",
    "y = train_data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3bcb95-6f43-4562-a2af-eeaabc71dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding_Scratch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e8ad5c-dfc7-47ac-bd47-5b1dda9d3488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 1.4541, -1.0955, -0.5818, -1.1664,  1.9851,  0.6057,  1.1191,  1.0689,\n",
       "                        1.0880,  0.1913, -1.0502,  0.1446,  0.6950, -1.3089,  0.1055, -1.2217,\n",
       "                       -0.6265,  2.2836, -1.3186, -0.4641],\n",
       "                      [-1.0683, -0.5650, -0.6572,  0.1054, -0.5782,  0.2241, -1.5169,  1.3078,\n",
       "                       -0.0769,  0.7008, -1.9838,  0.5673, -0.8595, -2.1326, -0.6864, -0.6746,\n",
       "                        0.4995, -0.2576, -0.7156, -1.2703],\n",
       "                      [-0.8015,  1.4487,  0.2416, -0.1133,  1.6529,  0.0532, -0.2236,  0.2681,\n",
       "                        2.6695,  0.8156,  1.9102, -0.2560, -0.0401, -0.5461,  1.2636,  0.5680,\n",
       "                        0.5692,  0.3456,  0.2229, -0.4243],\n",
       "                      [-1.0524, -0.1332, -0.4791, -0.2953,  1.1115, -0.7103,  0.9557, -2.0772,\n",
       "                       -0.5244, -0.9411,  1.8240,  1.0541,  0.9309, -0.7129,  0.9434,  0.2365,\n",
       "                        0.5055, -0.5295, -0.0266,  0.2037],\n",
       "                      [-0.1100,  1.5037, -1.6435, -1.2956, -0.3162, -0.7170,  0.5759, -0.4943,\n",
       "                       -0.0490,  0.2468, -0.5640,  0.7750,  1.0506,  0.2504,  0.4314, -1.0018,\n",
       "                        0.1357, -1.0411, -0.3224,  1.2590],\n",
       "                      [ 0.6768,  0.3753, -0.6418, -0.0168, -1.1435,  1.9271, -0.2697,  2.0447,\n",
       "                        0.7436, -0.1207,  0.7406,  0.6417, -1.9116, -1.4216, -1.8826,  1.0926,\n",
       "                        0.1080,  0.0487, -1.2616,  0.9202],\n",
       "                      [ 0.0928, -0.4162,  0.1057, -0.2338, -0.8242, -1.8451,  0.4421, -1.2260,\n",
       "                       -0.2812, -0.2657,  0.2515,  1.0274,  0.1332,  0.3783, -1.4217,  1.0451,\n",
       "                       -0.3675, -0.7764,  1.2023, -0.5809],\n",
       "                      [ 0.5938, -0.3104, -0.0989,  1.0907,  0.6705, -0.9277,  0.3934,  0.3265,\n",
       "                       -1.3945, -0.5338,  1.2862,  1.1009, -0.7684, -0.2547, -0.2173, -0.2206,\n",
       "                       -2.2924, -0.2836, -0.3884,  0.8118],\n",
       "                      [-0.2326,  1.5369,  1.2834,  1.1541,  2.8534, -0.3920,  1.7686, -0.0493,\n",
       "                       -2.0515,  0.0088, -1.2536, -0.5505, -0.5683, -0.5931,  0.2951, -0.2765,\n",
       "                       -0.0104, -0.5492, -1.1833, -1.1862],\n",
       "                      [ 1.3929,  0.1022,  0.0805, -0.8597, -0.4173,  1.1440, -2.3467,  1.0412,\n",
       "                        1.4959,  1.5271,  0.2768, -1.0249, -1.0129,  2.0368, -1.2700, -0.3982,\n",
       "                       -0.1963,  1.9193, -2.2541,  0.5416]]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 20)\n",
    "\n",
    "embedding.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8f648-32a4-4df6-a9ef-ee8a76de78f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
