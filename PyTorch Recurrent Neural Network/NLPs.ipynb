{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9436490-76dc-4c94-a63b-146743920419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976fc0f6-790f-483d-a5ca-1a6ea05660be",
   "metadata": {},
   "source": [
    "#### NLPs\n",
    "***\n",
    "- NLP (Natural Language Processing) is a machine learning model that is used to read and understand text\n",
    "\n",
    "#### Process of NLP Implementation\n",
    "***\n",
    "1. Loading the data\n",
    "2. Preprocessing\n",
    "3. Tokenization\n",
    "4. Word Embedding\n",
    "5. Implementing Recurrent Neural Network\n",
    "6. Hyperparameter Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb2ac7-2fcb-4e92-8f50-718503d1aeef",
   "metadata": {},
   "source": [
    "#### 1. Loading the Data\n",
    "***\n",
    "- Going to be using IMDBs movie review dataset\n",
    "- Using `Pandas` to read through csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6966fbb-02b3-4cb3-8f63-788edab90721",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv(r\"C:\\Users\\Brand\\project_env\\PyTorch Recurrent Neural Network\\data\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e3a618c-2e6e-422b-ba1c-f81027016f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b2a1b-1df0-47d1-aece-e004ba2b60ff",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing of an NLP\n",
    "***\n",
    "- lowercasing words and removing html tags or punctuations\n",
    "- Tokenization breaks a sentence into individual units of words or phrases. \n",
    "- Stemming and lemmatization simplify words into their root form. For example, these processes turn \"starting\" into \"start.\" \n",
    "- Stop word removal ensures that words that do not add significant meaning to a sentence, such as \"for\" and \"with,\" are removed\n",
    "\n",
    "\n",
    "Step by Step Process of Text Preprocessing: [GeekByGeek Text Preprocessing Tutorial](https://www.geeksforgeeks.org/text-preprocessing-in-python-set-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1eacd2b1-f706-4757-9b65-2ae9a6e6d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36e54587-56f3-4e8c-96de-aa193c23658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'wonder',\n",
       " 'littl',\n",
       " 'product',\n",
       " 'the',\n",
       " 'film',\n",
       " 'techniqu',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'unassum',\n",
       " 'veri',\n",
       " 'old',\n",
       " 'time',\n",
       " 'bbc',\n",
       " 'fashion',\n",
       " 'and',\n",
       " 'give',\n",
       " 'a',\n",
       " 'comfort',\n",
       " 'and',\n",
       " 'sometim',\n",
       " 'discomfort',\n",
       " 'sens',\n",
       " 'of',\n",
       " 'realism',\n",
       " 'to',\n",
       " 'the',\n",
       " 'entir',\n",
       " 'piec',\n",
       " 'the',\n",
       " 'actor',\n",
       " 'are',\n",
       " 'extrem',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'not',\n",
       " 'onli',\n",
       " 'ha',\n",
       " 'got',\n",
       " 'all',\n",
       " 'the',\n",
       " 'polari',\n",
       " 'but',\n",
       " 'he',\n",
       " 'ha',\n",
       " 'all',\n",
       " 'the',\n",
       " 'voic',\n",
       " 'down',\n",
       " 'pat',\n",
       " 'too',\n",
       " 'you',\n",
       " 'can',\n",
       " 'truli',\n",
       " 'see',\n",
       " 'the',\n",
       " 'seamless',\n",
       " 'edit',\n",
       " 'guid',\n",
       " 'by',\n",
       " 'the',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'william',\n",
       " 'diari',\n",
       " 'entri',\n",
       " 'not',\n",
       " 'onli',\n",
       " 'is',\n",
       " 'it',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'the',\n",
       " 'watch',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrificli',\n",
       " 'written',\n",
       " 'and',\n",
       " 'perform',\n",
       " 'piec',\n",
       " 'a',\n",
       " 'master',\n",
       " 'product',\n",
       " 'about',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'master',\n",
       " 's',\n",
       " 'of',\n",
       " 'comedi',\n",
       " 'and',\n",
       " 'hi',\n",
       " 'life',\n",
       " 'the',\n",
       " 'realism',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'home',\n",
       " 'with',\n",
       " 'the',\n",
       " 'littl',\n",
       " 'thing',\n",
       " 'the',\n",
       " 'fantasi',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guard',\n",
       " 'which',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'use',\n",
       " 'the',\n",
       " 'tradit',\n",
       " 'dream',\n",
       " 'techniqu',\n",
       " 'remain',\n",
       " 'solid',\n",
       " 'then',\n",
       " 'disappear',\n",
       " 'it',\n",
       " 'play',\n",
       " 'on',\n",
       " 'our',\n",
       " 'knowledg',\n",
       " 'and',\n",
       " 'our',\n",
       " 'sens',\n",
       " 'particularli',\n",
       " 'with',\n",
       " 'the',\n",
       " 'scene',\n",
       " 'concern',\n",
       " 'orton',\n",
       " 'and',\n",
       " 'halliwel',\n",
       " 'and',\n",
       " 'the',\n",
       " 'set',\n",
       " 'particularli',\n",
       " 'of',\n",
       " 'their',\n",
       " 'flat',\n",
       " 'with',\n",
       " 'halliwel',\n",
       " 's',\n",
       " 'mural',\n",
       " 'decor',\n",
       " 'everi',\n",
       " 'surfac',\n",
       " 'are',\n",
       " 'terribl',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove html tags\n",
    "\n",
    "\n",
    "imdb_data.review.iloc[1]\n",
    "\n",
    "HTML_TAGS = re.compile(\"<[^>]+>\")\n",
    "\n",
    "def remove_tags(text):\n",
    "    return HTML_TAGS.sub(\"\", text)\n",
    "\n",
    "def stem_words(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return stems\n",
    "\n",
    "remove_tags(imdb_data.review.iloc[1])\n",
    "\n",
    "sentence = re.sub(\"[^a-zA-Z]\", \" \", remove_tags(imdb_data.review.iloc[1])).lower()\n",
    "\n",
    "sentence = re.sub(r'\\d+', '', sentence)\n",
    "\n",
    "stem_words(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b56df7-9e9f-4abc-b114-5ef088dbf723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
