{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caef77d-97c0-48c6-ac59-b43b2f9b2241",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "***\n",
    "\n",
    "- Word embedding is a method used to find relations between vectors\n",
    "- Typically defined as a way to convert words to context vectors\n",
    "- Vectors that are similar, means the words are similar in context :D\n",
    "\n",
    "**Preprocessing**\n",
    "1. `Load in Data`\n",
    "2. `Remove Stop Words`\n",
    "3. `Convert to Bigram`\n",
    "4. `Convert Bigram to One-Hot-Encodings`\n",
    "\n",
    "**Training**\n",
    "1. `Split Bigram to Train, Test Data`\n",
    "2. `Create Linear Model`\n",
    "3. `Obtain Weights After Training`\n",
    "4. `Vizualize Points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2064474-61c5-4c98-9bea-9ae7706449a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brand\\AppData\\Local\\Temp\\ipykernel_5720\\208067942.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d61f7c9-f951-47ec-a164-542d1f3f121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = [\"is\", \"a\", \"has\", \"an\"]\n",
    "\n",
    "    removed_stop_words_list = []\n",
    "    \n",
    "    for i, _ in enumerate(data):\n",
    "        removed_stop_words_list.append([word for word in data[i].replace(\"\\n\", \"\").split(\" \") if word not in stop_words])\n",
    "\n",
    "    return removed_stop_words_list\n",
    "                \n",
    "def bigrams(data):\n",
    "    bigram_list = []\n",
    "\n",
    "    for _, word in enumerate(data):\n",
    "        for j in range(len(word) - 1):\n",
    "            bigram_list.append(word[j : j+2])\n",
    "    \n",
    "    return bigram_list\n",
    "\n",
    "def vocabulary(bigram_data):\n",
    "    vocab_list = []\n",
    "    for bigram in bigram_data:\n",
    "        vocab_list.extend(bigram)\n",
    "\n",
    "    return list(set(vocab_list))\n",
    "\n",
    "def one_hot_encoder(vocab_data, bigram_data):\n",
    "    one_hot_values = {}\n",
    "    bigram_one_hot_list = []\n",
    "    for i, key in enumerate(vocab_data):\n",
    "        one_hot_values[key] = [0 if i != j else 1 for j in range(len(vocab_data))]\n",
    "\n",
    "    print(\"One Hot Encoder\\n------------\\n\")\n",
    "    print(np.array([f\"{key}: {value}\" for key, value in one_hot_values.items()]))\n",
    "    for i, (X,y) in enumerate(bigram_data):\n",
    "        # print(bigram_data[i])\n",
    "        bigram_one_hot_list.append([one_hot_values[X], one_hot_values[y]])\n",
    "\n",
    "    return np.array(bigram_one_hot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a45e4d-25a0-4ce6-b75c-85baec5428da",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "1. Load in Data\n",
    "   - Using a default txt file with a bunch of names and adjectives\n",
    "   - Python's **`open()`** function will open the text file\n",
    "   - **`readlines()`** function will split the text file by new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ee40209-8c3e-4525-9061-54aa8c6e288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"text_data.txt\", \"r\")\n",
    "data = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cf882-1571-457e-8d5f-b8f6ba6f3ca3",
   "metadata": {},
   "source": [
    "2. Remove Stop Words\n",
    "   - Using our built function **`remove_stop_words()`**, it cleans the sentence (removes \"\\n\")\n",
    "   - Then, removes stop words (\"is\", \"a\", \"an\", \"has\") from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42e39f1b-5e16-42ab-a773-82eaa4d71c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Branden', 'good', 'person'],\n",
       " ['Shlok', 'great', 'man'],\n",
       " ['Jason', 'nice', 'person'],\n",
       " ['David', 'bad', 'human'],\n",
       " ['Chris', 'great', 'personality'],\n",
       " ['Sara', 'interesting', 'woman']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = remove_stop_words(data)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06f4b6-8ad5-469f-8302-ff16bdfcfcd6",
   "metadata": {},
   "source": [
    "3. Bigrams\n",
    "   - Using our built function **`bigrams()`**, it converts our newly cleaned txt_data to bigrams\n",
    "   - We will use sliding window technique to get all the bigrams\n",
    "   <br></br>\n",
    "  \n",
    "**What is Bigrams**\n",
    "- A sequence of two words, the first value being the feature and the seconds value being the label\n",
    "- Example: \"I am great\" will become (\"I\", \"am\") and (\"am great\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44586499-2bcd-43eb-9592-e7f65a7c9175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Branden', 'good'],\n",
       " ['good', 'person'],\n",
       " ['Shlok', 'great'],\n",
       " ['great', 'man'],\n",
       " ['Jason', 'nice'],\n",
       " ['nice', 'person'],\n",
       " ['David', 'bad'],\n",
       " ['bad', 'human'],\n",
       " ['Chris', 'great'],\n",
       " ['great', 'personality'],\n",
       " ['Sara', 'interesting'],\n",
       " ['interesting', 'woman']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = bigrams(cleaned_data)\n",
    "vocab_data = vocabulary(bigram_data)\n",
    "\n",
    "bigram_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b67533-e4fa-4d25-8d38-2d93c8ee9faa",
   "metadata": {},
   "source": [
    "4. Convert Bigrams to One-Hot-Encodings\n",
    "   - Using our built function **`one_hot_encoder()`**, it cleans the sentence (removes \"\\n\")\n",
    "   - Then, removes stop words (\"is\", \"a\", \"an\", \"has\") from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a989024-18ef-4ed2-ae16-9235497596f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoder\n",
      "------------\n",
      "\n",
      "['interesting: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'great: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'person: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'personality: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'Branden: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'Sara: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'David: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'human: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'Shlok: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]'\n",
      " 'Chris: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]'\n",
      " 'Jason: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]'\n",
      " 'bad: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]'\n",
      " 'woman: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]'\n",
      " 'nice: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]'\n",
      " 'man: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]'\n",
      " 'good: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]']\n"
     ]
    }
   ],
   "source": [
    "train_data = one_hot_encoder(vocab_data, bigram_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e3598-1077-416a-b39a-2ddc866297e8",
   "metadata": {},
   "source": [
    "#### Training\n",
    "1. Splitting the data into features and labsl\n",
    "   - Using **`numpy.array()`** to split the data by column\n",
    "   - `X` represents our features\n",
    "   - `y` represents our labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22acc264-ee4f-45e4-b5c6-4f76b32f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[:, 0]\n",
    "y = train_data[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0d0ea-0d05-470f-ba90-17a6b0226d9c",
   "metadata": {},
   "source": [
    "2. Creating the Model\n",
    "   - Using **`nn.Module`** to create our EmbeddingScratch Model\n",
    "\n",
    "**Attributes**\n",
    "- `vocab_size`: the total unique words in our bigrams\n",
    "- `embed_size`: the size of our word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3bcb95-6f43-4562-a2af-eeaabc71dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding_Scratch(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(vocab_size, embed_size)\n",
    "        self.output_layer = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4f0d2-4c97-4bc2-8085-632a2f7ac707",
   "metadata": {},
   "source": [
    "3. Initializing the Optimizer and Loss Function\n",
    "    - Using Pytorch's **`nn.CrossEntropyLoss()`** and **`torch.optim.Adam()`** to create our loss function and optimization algorithm\n",
    "  \n",
    "   \n",
    "**Optimizer**\n",
    "- Adam Algorithm to optimize our model\n",
    "\n",
    "**Loss Function**\n",
    "- Cross Entropy Loss function to calculate the loss\n",
    "- We use Cross Entropy Loss because we are predicting categories (words in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cb12e27-f086-44f5-9571-d0882fb43f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = y.shape[1]\n",
    "print(vocab_size)\n",
    "# -- Hyperparameter -- #\n",
    "EMBED_SIZE = 3\n",
    "LR = 0.01\n",
    "\n",
    "word_embedding_scratch = Embedding_Scratch(vocab_size, EMBED_SIZE)\n",
    "word_embedding_scratch.to(device) # sets the model into the gpu\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=word_embedding_scratch.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07ef9d2e-8f1f-43f6-b95b-fba02ed89db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X,y, criterion, optimizer, epoches):\n",
    "    for i in tqdm(range(epoches)):\n",
    "        train_loss = 0\n",
    "        \n",
    "        model.train()\n",
    "        for j, _ in enumerate(X):\n",
    "            y_pred = model(torch.IntTensor(X[j]).to(device))\n",
    "            loss = criterion(y_pred, torch.Tensor(y[j]).to(device))\n",
    "            train_loss += loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(X)\n",
    "        if i % 100 == 0 or i == epoches - 1:\n",
    "            print(f\"Epoch {i} - Train Loss {train_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "febeeccf-ce66-4fcf-aaff-886637c99569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9be3dfb528a4cd9b9260bee097391e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss 2.8747\n",
      "Epoch 100 - Train Loss 0.1458\n",
      "Epoch 200 - Train Loss 0.1250\n",
      "Epoch 300 - Train Loss 0.1216\n",
      "Epoch 400 - Train Loss 0.1201\n",
      "Epoch 500 - Train Loss 0.1192\n",
      "Epoch 600 - Train Loss 0.1186\n",
      "Epoch 700 - Train Loss 0.1181\n",
      "Epoch 800 - Train Loss 0.1177\n",
      "Epoch 900 - Train Loss 0.1174\n",
      "Epoch 999 - Train Loss 0.1171\n"
     ]
    }
   ],
   "source": [
    "train_model(word_embedding_scratch, X, y, criterion, optimizer, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73904db7-fbfd-410d-a2e2-1f4691e7d4c8",
   "metadata": {},
   "source": [
    "4. Plotting and Visualizing the Context Vectors\n",
    "   - **`Pandas.DataFrame`** to create a dataframe of context vectors\n",
    "   - **`Seaborn`** to create a scatterplot of our context vectors\n",
    "   - **`Matplotlib.pyplot`** to create annotate and label our context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffafe0f1-2e59-44c7-86cc-f894759b8e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>interesting</th>\n",
       "      <td>2.009850</td>\n",
       "      <td>-4.984304</td>\n",
       "      <td>-6.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>-4.320120</td>\n",
       "      <td>-4.624294</td>\n",
       "      <td>-0.655854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>1.773709</td>\n",
       "      <td>-2.901454</td>\n",
       "      <td>3.198857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personality</th>\n",
       "      <td>1.294889</td>\n",
       "      <td>1.491018</td>\n",
       "      <td>-1.300258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branden</th>\n",
       "      <td>-1.424791</td>\n",
       "      <td>-4.430124</td>\n",
       "      <td>-1.150826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sara</th>\n",
       "      <td>-1.483765</td>\n",
       "      <td>-4.400043</td>\n",
       "      <td>-1.276718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>-1.430115</td>\n",
       "      <td>-4.445275</td>\n",
       "      <td>-1.217248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>-2.883605</td>\n",
       "      <td>-2.803594</td>\n",
       "      <td>2.371482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shlok</th>\n",
       "      <td>-1.554888</td>\n",
       "      <td>-4.360596</td>\n",
       "      <td>-1.249657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>-1.478031</td>\n",
       "      <td>-4.410026</td>\n",
       "      <td>-1.187339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jason</th>\n",
       "      <td>-1.532624</td>\n",
       "      <td>-4.357460</td>\n",
       "      <td>-1.205979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>3.522005</td>\n",
       "      <td>-5.027224</td>\n",
       "      <td>-0.404199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>-3.208130</td>\n",
       "      <td>-3.833751</td>\n",
       "      <td>-6.298779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>-5.080138</td>\n",
       "      <td>-1.354391</td>\n",
       "      <td>-1.572164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.295600</td>\n",
       "      <td>1.505960</td>\n",
       "      <td>-1.300104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>-0.357907</td>\n",
       "      <td>-5.163614</td>\n",
       "      <td>1.927809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2\n",
       "interesting  2.009850 -4.984304 -6.003368\n",
       "great       -4.320120 -4.624294 -0.655854\n",
       "person       1.773709 -2.901454  3.198857\n",
       "personality  1.294889  1.491018 -1.300258\n",
       "Branden     -1.424791 -4.430124 -1.150826\n",
       "Sara        -1.483765 -4.400043 -1.276718\n",
       "David       -1.430115 -4.445275 -1.217248\n",
       "human       -2.883605 -2.803594  2.371482\n",
       "Shlok       -1.554888 -4.360596 -1.249657\n",
       "Chris       -1.478031 -4.410026 -1.187339\n",
       "Jason       -1.532624 -4.357460 -1.205979\n",
       "bad          3.522005 -5.027224 -0.404199\n",
       "woman       -3.208130 -3.833751 -6.298779\n",
       "nice        -5.080138 -1.354391 -1.572164\n",
       "man          1.295600  1.505960 -1.300104\n",
       "good        -0.357907 -5.163614  1.927809"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = word_embedding_scratch.state_dict()[\"output_layer.weight\"]\n",
    "\n",
    "context_vector_df = pd.DataFrame(context_vectors.cpu().detach().numpy())\n",
    "context_vector_df.index = vocab_data\n",
    "\n",
    "context_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eea8cef3-eb68-4fc9-9f98-85918c14fda6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vocab_data):\n\u001b[0;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m context_vectors\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 10\u001b[0m     \u001b[43membedding_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:711\u001b[0m, in \u001b[0;36mAxes.annotate\u001b[1;34m(self, text, xy, xytext, xycoords, textcoords, arrowprops, annotation_clip, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannotate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, xy, xytext\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, xycoords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, textcoords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    708\u001b[0m              arrowprops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, annotation_clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;66;03m# Signature must match Annotation. This is verified in\u001b[39;00m\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# test_annotate_signature().\u001b[39;00m\n\u001b[1;32m--> 711\u001b[0m     a \u001b[38;5;241m=\u001b[39m mtext\u001b[38;5;241m.\u001b[39mAnnotation(text, xy, xytext\u001b[38;5;241m=\u001b[39mxytext, xycoords\u001b[38;5;241m=\u001b[39mxycoords,\n\u001b[0;32m    712\u001b[0m                          textcoords\u001b[38;5;241m=\u001b[39mtextcoords, arrowprops\u001b[38;5;241m=\u001b[39marrowprops,\n\u001b[0;32m    713\u001b[0m                          annotation_clip\u001b[38;5;241m=\u001b[39mannotation_clip, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    714\u001b[0m     a\u001b[38;5;241m.\u001b[39mset_transform(mtransforms\u001b[38;5;241m.\u001b[39mIdentityTransform())\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_on\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\matplotlib\\text.py:1805\u001b[0m, in \u001b[0;36mAnnotation.__init__\u001b[1;34m(self, text, xy, xytext, xycoords, textcoords, arrowprops, annotation_clip, **kwargs)\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, xy,\n\u001b[0;32m   1634\u001b[0m              xytext\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1635\u001b[0m              xycoords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m              annotation_clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1639\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;124;03m    Annotate the point *xy* with text *text*.\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1803\u001b[0m \n\u001b[0;32m   1804\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1805\u001b[0m     \u001b[43m_AnnotationBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mxycoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxycoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mannotation_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1809\u001b[0m     \u001b[38;5;66;03m# warn about wonky input data\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (xytext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m             textcoords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m             textcoords \u001b[38;5;241m!=\u001b[39m xycoords):\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\matplotlib\\text.py:1450\u001b[0m, in \u001b[0;36m_AnnotationBase.__init__\u001b[1;34m(self, xy, xycoords, annotation_clip)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1446\u001b[0m              xy,\n\u001b[0;32m   1447\u001b[0m              xycoords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1448\u001b[0m              annotation_clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1450\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m xy  \u001b[38;5;66;03m# Make copy when xy is an array (and check the shape).\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxy \u001b[38;5;241m=\u001b[39m x, y\n\u001b[0;32m   1452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxycoords \u001b[38;5;241m=\u001b[39m xycoords\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "embedding_graph = sns.scatterplot(data=context_vector_df, x=context_vector_df[0], y=context_vector_df[1])\n",
    "\n",
    "for i, word in enumerate(vocab_data):\n",
    "    data = context_vectors.cpu().detach().numpy()\n",
    "    embedding_graph.annotate(word, tuple(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d04f02e-4042-4e86-b390-3af4c6d17cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.8212,  0.0199, -2.0618],\n",
       "                      [-0.7725,  0.0558,  0.6837],\n",
       "                      [ 1.2496,  1.5464, -0.6298],\n",
       "                      [ 2.1904,  0.3164, -0.1985],\n",
       "                      [-0.1003,  1.1369, -0.8063],\n",
       "                      [-0.3516, -1.0496,  0.2188],\n",
       "                      [-0.2127, -0.6794, -1.7814],\n",
       "                      [ 2.2613,  0.2305, -0.5974],\n",
       "                      [ 1.3887, -1.1365, -1.0111],\n",
       "                      [ 0.5299,  0.1714,  0.1929],\n",
       "                      [-0.3169,  0.8191,  1.4429],\n",
       "                      [ 0.9071,  2.0797, -0.2416],\n",
       "                      [-0.7480, -0.3190, -1.6438],\n",
       "                      [ 0.0028, -0.6094, -0.1208],\n",
       "                      [ 0.9010, -0.3563, -0.3057],\n",
       "                      [-1.0496, -0.7184,  0.6261]]))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(16, 3)\n",
    "embedding.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "535bf471-1976-46f2-8ad6-08737a8b920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_data = torch.arange(16)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.l_0 = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.l_0(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50ab04be-e6ee-4f9a-9323-69cd3d537e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cde8081d8641bd8b0a4a1186f903eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m pytorch_embedding\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mpytorch_embedding\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X, y, criterion, optimizer, epoches)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mIntTensor(X[j])\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\project_env\\lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "pytorch_embedding = Embedding(16, 3)\n",
    "pytorch_embedding.to(device)\n",
    "optimizer = torch.optim.Adam(params=pytorch_embedding.parameters(), lr=LR)\n",
    "train_model(pytorch_embedding, X, y, criterion, optimizer, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
