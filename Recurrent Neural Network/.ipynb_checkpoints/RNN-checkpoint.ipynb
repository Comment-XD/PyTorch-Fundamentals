{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ed4ef7-c166-4214-a429-c243dbf6c9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchinfo\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7555b-36f7-4687-82bc-8cd89a2ffa15",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f5275be-dbba-4154-87bb-93edcf09328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Scratch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.waa = nn.Parameter(torch.rand(hidden_size, hidden_size), requires_grad=True).to(device)\n",
    "        self.baa = nn.Parameter(torch.rand(1)).to(device)\n",
    "        \n",
    "        self.wax = nn.Parameter(torch.rand(hidden_size, input_size), requires_grad=True).to(device)\n",
    "        self.bax = nn.Parameter(torch.rand(1)).to(device)\n",
    "        \n",
    "        self.way = nn.Parameter(torch.rand(hidden_size, hidden_size), requires_grad=True).to(device)\n",
    "        self.bay = nn.Parameter(torch.rand(1)).to(device)\n",
    "\n",
    "    def forward(self, x_input, hidden_input=None):\n",
    "        x_input = x_input.to(device)\n",
    "        \n",
    "        hidden_input = torch.zeros(1, self.hidden_size).to(device) if not hidden_input else hidden_input\n",
    "        h_val = torch.matmul(hidden_input, self.waa.T) + self.baa\n",
    "        x_val = torch.matmul(x_input, self.wax.T) + self.bax\n",
    "        # print(h_val.shape, x_val.shape)\n",
    "\n",
    "        a_val = torch.tanh(h_val + x_val)\n",
    "        z = torch.matmul(a_val, self.way.T) + self.bay\n",
    "        y_val = torch.nn.Softmax(dim=1)(z)\n",
    "\n",
    "        return a_val, a_val[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc10e3-f50d-46ba-a8b4-100df55fbc06",
   "metadata": {},
   "source": [
    "# Pytorch RNN\n",
    "***\n",
    "\n",
    "**`nn.RNN(input_size, hidden_state, num_layers)`**\n",
    "- `input_size`: the number of expect feature in the input x\n",
    "- `hidden_size`: the number of features in the hidden state\n",
    "- `num_layers`: the number of recurrent layers \n",
    "    <br></br>\n",
    "1. `.forward(inputs, hidden_state=torch.zeros(1, hidden_state)))`\n",
    "    - forward has two inputs, the previous activation layer and the input values\n",
    "    - for the previous activation layer, when set to a dimension, create a zero vector of that dimension as its default value\n",
    "    - inputs: represents the data you want to look through\n",
    "\n",
    "\n",
    "2. **`Math` behind .foward()**\n",
    "   - `input_size` = $x_t$\n",
    "   - `input` = $[1 \\text{ x } x_t]$\n",
    "   - `input_bias` = $b_x$\n",
    "   - `input_weights` = $w_{x}$\n",
    "   - `hidden_size` = $h_t$\n",
    "   - `hidden` = $[1 \\text{ x } h_t]$\n",
    "   - `hidden_bias` = $b_h$\n",
    "   - `hidden_weights` = $w_{h}$\n",
    "\n",
    "$$\n",
    "a_t = f((x_t * w_t.T + b_x) + (h_t * w_h.T + b_h)\n",
    "$$\n",
    "\n",
    "\n",
    "- Input: $X = [1 \\text{ x } x_t] $ and input weights $W_{ax} = [x_t \\text{ x } h_t]$ Dimensions\n",
    "- Hidden input: $H = [1 \\text{ x } h_t]$ and hidden weights $[h_t \\text{ x } h_t]$ Dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c24ec1c0-bdeb-400e-ad4f-7803878f0849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150],\n",
       "        [0.3829, 0.9593],\n",
       "        [0.3904, 0.6009],\n",
       "        [0.2566, 0.7936],\n",
       "        [0.9408, 0.1332],\n",
       "        [0.9346, 0.5936],\n",
       "        [0.8694, 0.5677],\n",
       "        [0.7411, 0.4294],\n",
       "        [0.8854, 0.5739],\n",
       "        [0.2666, 0.6274],\n",
       "        [0.2696, 0.4414],\n",
       "        [0.2969, 0.8317],\n",
       "        [0.1053, 0.2695],\n",
       "        [0.3588, 0.1994],\n",
       "        [0.5472, 0.0062],\n",
       "        [0.9516, 0.0753],\n",
       "        [0.8860, 0.5832],\n",
       "        [0.3376, 0.8090],\n",
       "        [0.5779, 0.9040],\n",
       "        [0.5547, 0.3423],\n",
       "        [0.6343, 0.3644],\n",
       "        [0.7104, 0.9464],\n",
       "        [0.7890, 0.2814],\n",
       "        [0.7886, 0.5895],\n",
       "        [0.7539, 0.1952],\n",
       "        [0.0050, 0.3068],\n",
       "        [0.1165, 0.9103],\n",
       "        [0.6440, 0.7071],\n",
       "        [0.6581, 0.4913],\n",
       "        [0.8913, 0.1447]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "data = torch.rand(30, 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e957b412-1b31-4c5d-9014-ee3f0d9c4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6542, 0.3278]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([[0.5315]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([0.6532], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([0.1587], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9340],\n",
       "         [0.8802],\n",
       "         [0.8523],\n",
       "         [0.8454],\n",
       "         [0.8998],\n",
       "         [0.9243],\n",
       "         [0.9165],\n",
       "         [0.8932],\n",
       "         [0.9185],\n",
       "         [0.8312],\n",
       "         [0.8120],\n",
       "         [0.8562],\n",
       "         [0.7483],\n",
       "         [0.8048],\n",
       "         [0.8249],\n",
       "         [0.8975],\n",
       "         [0.9190],\n",
       "         [0.8612],\n",
       "         [0.9026],\n",
       "         [0.8583],\n",
       "         [0.8732],\n",
       "         [0.9197],\n",
       "         [0.8897],\n",
       "         [0.9089],\n",
       "         [0.8785],\n",
       "         [0.7239],\n",
       "         [0.8295],\n",
       "         [0.8986],\n",
       "         [0.8861],\n",
       "         [0.8942]], device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " tensor([0.8942], device='cuda:0', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_scratch = RNN_Scratch(2, 1)\n",
    "\n",
    "# rnn_scratch.wax = nn.Parameter(torch.Tensor([[-0.4683,  0.2004]])).to(device)\n",
    "# rnn_scratch.waa = nn.Parameter(torch.Tensor([[-0.6782]])).to(device)\n",
    "# rnn_scratch.bax = nn.Parameter(torch.Tensor([[0.4811]])).to(device)\n",
    "# rnn_scratch.wax = nn.Parameter(torch.Tensor([0.5583])).to(device)\n",
    "print(rnn_scratch.wax)\n",
    "print(rnn_scratch.waa)\n",
    "print(rnn_scratch.bax)\n",
    "print(rnn_scratch.baa)\n",
    "rnn_scratch.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d564e92f-c0ab-4b82-ae33-d5de6c54e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight_ih_l0', tensor([[-0.6367,  0.9996]])), ('weight_hh_l0', tensor([[0.1889]])), ('bias_ih_l0', tensor([0.3082])), ('bias_hh_l0', tensor([-0.9327]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2652],\n",
       "         [ 0.0405],\n",
       "         [-0.2588],\n",
       "         [-0.0434],\n",
       "         [-0.8000],\n",
       "         [-0.6512],\n",
       "         [-0.6253],\n",
       "         [-0.6557],\n",
       "         [-0.6282],\n",
       "         [-0.2782],\n",
       "         [-0.3864],\n",
       "         [-0.0552],\n",
       "         [-0.4075],\n",
       "         [-0.6235],\n",
       "         [-0.7949],\n",
       "         [-0.8631],\n",
       "         [-0.6462],\n",
       "         [-0.1517],\n",
       "         [-0.1170],\n",
       "         [-0.5768],\n",
       "         [-0.6487],\n",
       "         [-0.2481],\n",
       "         [-0.7126],\n",
       "         [-0.5863],\n",
       "         [-0.7699],\n",
       "         [-0.4353],\n",
       "         [ 0.1283],\n",
       "         [-0.2945],\n",
       "         [-0.5428],\n",
       "         [-0.8177]], grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.8177]], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(2, 1)\n",
    "print(rnn.state_dict())\n",
    "rnn.forward(data) # returns the hiddent state, cell_state, and predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda2b53-8c82-419f-bfae-acf88dc7d5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
